{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61912fa9",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from ultralytics.models import YOLO\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab13785",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cd42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path (created by e2e_data_prep.ipynb)\n",
    "YOLO_DATASET = Path(\"datasets/ready/full_dataset\")\n",
    "RUNS_DIR = Path(\"runs/segment\")\n",
    "\n",
    "# Verify dataset exists\n",
    "if not YOLO_DATASET.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at {YOLO_DATASET}. Run e2e_data_prep.ipynb first!\")\n",
    "\n",
    "print(f\"Dataset: {YOLO_DATASET}\")\n",
    "print(f\"  Train: {YOLO_DATASET / 'train'}\")\n",
    "print(f\"  Val: {YOLO_DATASET / 'val'}\")\n",
    "print(f\"  Test: {YOLO_DATASET / 'test'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9818581c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 640\n",
    "model_type = \"yolo11n-seg.pt\"\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49612aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG_CONFIG = {\n",
    "    'hsv_h': 0.015,  # Hue augmentation\n",
    "    'hsv_s': 0.7,    # Saturation\n",
    "    'hsv_v': 0.4,    # Value\n",
    "    'degrees': 10.0,  # Rotation\n",
    "    'translate': 0.1, # Translation\n",
    "    'scale': 0.5,     # Scaling\n",
    "    'shear': 0.0,     # Shearing\n",
    "    'perspective': 0.0, # Perspective\n",
    "    'flipud': 0.0,    # Vertical flip\n",
    "    'fliplr': 0.5,    # Horizontal flip\n",
    "    'mosaic': 1.0,    # Mosaic augmentation\n",
    "    'mixup': 0.0,     # Mixup augmentation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b37a05",
   "metadata": {},
   "source": [
    "## Step 3: Verify Dataset Structure\n",
    "\n",
    "Dataset is already prepared by e2e_data_prep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b684ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "stats = {}\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = YOLO_DATASET / split / \"images\"\n",
    "    lbl_dir = YOLO_DATASET / split / \"labels\"\n",
    "    \n",
    "    if img_dir.exists() and lbl_dir.exists():\n",
    "        num_images = len(list(img_dir.glob(\"*\")))\n",
    "        num_labels = len(list(lbl_dir.glob(\"*.txt\")))\n",
    "        stats[split] = {'images': num_images, 'labels': num_labels}\n",
    "        print(f\"{split.upper():5s}: {num_images:4d} images, {num_labels:4d} labels\")\n",
    "    else:\n",
    "        stats[split] = {'images': 0, 'labels': 0}\n",
    "        print(f\"{split.upper():5s}: Missing!\")\n",
    "\n",
    "total_images = sum(s['images'] for s in stats.values())\n",
    "total_labels = sum(s['labels'] for s in stats.values())\n",
    "\n",
    "print(f\"{'TOTAL':5s}: {total_images:4d} images, {total_labels:4d} labels\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if total_images == 0:\n",
    "    raise RuntimeError(\"No dataset found! Run e2e_data_prep.ipynb to create the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b201a0",
   "metadata": {},
   "source": [
    "## Step 4: Create YOLO Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95ce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    'red ball': 0,\n",
    "    'human': 1,\n",
    "    'trashcan': 2\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'path': str(YOLO_DATASET.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'nc': len(classes),\n",
    "    'names': list(classes.keys())\n",
    "}\n",
    "\n",
    "config_path = YOLO_DATASET / 'data.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"âœ“ Configuration saved: {config_path}\")\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(f\"  Train: {YOLO_DATASET / 'train'}\")\n",
    "print(f\"  Val: {YOLO_DATASET / 'val'}\")\n",
    "print(f\"  Test: {YOLO_DATASET / 'test'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef74bc8",
   "metadata": {},
   "source": [
    "## Step 5: Train Model\n",
    "\n",
    "Train YOLOv11 with:\n",
    "- Data augmentation on train set\n",
    "- Checkpoints saved for best model\n",
    "- Validation after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = YOLO(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_idx = next((i for i, m in enumerate(model.model.model) if 'Detect' in m.__class__.__name__ or 'Segment' in m.__class__.__name__), len(model.model.model) - 1)\n",
    "project_name = 'ball_person_model'\n",
    "results = model.train(\n",
    "    data=str(config_path),\n",
    "    epochs=500,\n",
    "    freeze=list(range(head_idx)),\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    project=str(RUNS_DIR),\n",
    "    name=project_name,\n",
    "    exist_ok=True,\n",
    "    \n",
    "    # Checkpointing\n",
    "    save=True,\n",
    "    save_period=1,  # Save every epoch\n",
    "    \n",
    "    # Validation\n",
    "    val=True,\n",
    "    \n",
    "    # Data augmentation (only applied to train)\n",
    "    **AUG_CONFIG,\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer='Adam',\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    # Loss weights\n",
    "    box=7.5,\n",
    "    cls=0.5,\n",
    "    dfl=1.5,\n",
    "    \n",
    "    # Other\n",
    "    patience=20,  # Early stopping\n",
    "    workers=8,\n",
    "\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbe082",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation metrics\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ“Š VALIDATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Box mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"Box mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Mask mAP50: {metrics.seg.map50:.4f}\")\n",
    "print(f\"Mask mAP50-95: {metrics.seg.map:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find best checkpoint\n",
    "model_dir = RUNS_DIR / 'ball_person_model'\n",
    "best_model = model_dir / 'weights' / 'best.pt'\n",
    "last_model = model_dir / 'weights' / 'last.pt'\n",
    "\n",
    "print(f\"\\nâœ… Training complete!\")\n",
    "print(f\"   Best model: {best_model}\")\n",
    "print(f\"   Last model: {last_model}\")\n",
    "print(f\"   Results: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fec1d1",
   "metadata": {},
   "source": [
    "## Step 7: Test on Sample Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8111c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42f9f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model_path = RUNS_DIR / 'ball_person_model' / 'weights' / 'last.pt'\n",
    "trained_model = YOLO(str(best_model_path))\n",
    "\n",
    "# Test on validation images (sample from val set)\n",
    "test_images = list((YOLO_DATASET / \"val\" / \"images\").glob(\"*\"))\n",
    "\n",
    "print(f\"Testing on {len(test_images)} sample images...\")\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = trained_model.predict(str(img_path), save=True, conf=0.25)\n",
    "    print(f\"  âœ“ {img_path.name}\")\n",
    "\n",
    "print(f\"\\nResults saved to: {RUNS_DIR / 'ball_person_model'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
