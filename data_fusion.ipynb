{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4873706",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc160272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeba9f2",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da28bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Output dataset: datasets/ready/combined_train\n"
     ]
    }
   ],
   "source": [
    "# Source datasets\n",
    "YAHOO_DATASET = Path(\"datasets/preprocessed/yahoo_human_balls/ready\")\n",
    "COCO_DATASET = Path(\"datasets/processed/coco_persons\")  # Existing COCO processing\n",
    "\n",
    "# Output dataset\n",
    "OUTPUT_DATASET = Path(\"datasets/ready/combined_train\")\n",
    "OUTPUT_IMAGES = OUTPUT_DATASET / \"images\"\n",
    "OUTPUT_LABELS = OUTPUT_DATASET / \"labels\"\n",
    "\n",
    "# Create output directories\n",
    "OUTPUT_IMAGES.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_LABELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"‚úì Output dataset: {OUTPUT_DATASET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8b7f9",
   "metadata": {},
   "source": [
    "## Step 3: Define Class Mapping\n",
    "\n",
    "Map source class names to unified class IDs:\n",
    "- 0: red ball\n",
    "- 1: human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97626307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class mapping:\n",
      "  0: red ball\n",
      "  1: human\n"
     ]
    }
   ],
   "source": [
    "CLASS_MAPPING = {\n",
    "    \"red ball\": 0,\n",
    "    \"human\": 1\n",
    "}\n",
    "\n",
    "CLASS_NAMES = [\"red ball\", \"human\"]\n",
    "\n",
    "print(\"Class mapping:\")\n",
    "for name, idx in CLASS_MAPPING.items():\n",
    "    print(f\"  {idx}: {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b31996",
   "metadata": {},
   "source": [
    "## Step 4: Copy Yahoo Dataset\n",
    "\n",
    "Copy images and labels from yahoo_human_balls dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222d9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_dataset_with_class_conversion(source_ready_path: Path, output_images: Path, output_labels: Path, class_mapping: dict):\n",
    "    \"\"\"\n",
    "    Copy a dataset in the new format (ready/images + ready/labels/{class}/)\n",
    "    to a unified format with class ID conversion\n",
    "    \"\"\"\n",
    "    source_images = source_ready_path / \"images\"\n",
    "    source_labels = source_ready_path / \"labels\"\n",
    "    \n",
    "    if not source_images.exists():\n",
    "        print(f\"‚ö†Ô∏è  No images found at {source_images}\")\n",
    "        return 0\n",
    "    \n",
    "    # Get all images\n",
    "    images = list(source_images.glob(\"*.jpg\")) + list(source_images.glob(\"*.jpeg\")) + \\\n",
    "             list(source_images.glob(\"*.JPG\")) + list(source_images.glob(\"*.JPEG\")) + \\\n",
    "             list(source_images.glob(\"*.png\")) + list(source_images.glob(\"*.PNG\"))\n",
    "    \n",
    "    print(f\"üìÅ Found {len(images)} images\")\n",
    "    \n",
    "    # Build image -> labels mapping\n",
    "    image_labels = defaultdict(list)\n",
    "    \n",
    "    for class_name, class_id in class_mapping.items():\n",
    "        class_label_dir = source_labels / class_name\n",
    "        if not class_label_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        txt_files = list(class_label_dir.glob(\"*.txt\"))\n",
    "        print(f\"  - {class_name} ({class_id}): {len(txt_files)} label files\")\n",
    "        \n",
    "        for txt_file in txt_files:\n",
    "            image_labels[txt_file.stem].append((class_id, txt_file))\n",
    "    \n",
    "    # Copy images and merge labels\n",
    "    copied_count = 0\n",
    "    \n",
    "    for img_path in tqdm(images, desc=\"Copying\"):\n",
    "        stem = img_path.stem\n",
    "        \n",
    "        # Copy image\n",
    "        dest_img = output_images / img_path.name\n",
    "        if not dest_img.exists():\n",
    "            shutil.copy(img_path, dest_img)\n",
    "        \n",
    "        # Merge all labels for this image\n",
    "        if stem in image_labels:\n",
    "            merged_labels = []\n",
    "            \n",
    "            for class_id, txt_file in image_labels[stem]:\n",
    "                with open(txt_file, 'r') as f:\n",
    "                    lines = f.readlines()\n",
    "                \n",
    "                # Convert class ID (first element of each line)\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if line:\n",
    "                        parts = line.split()\n",
    "                        # Replace class ID with our mapping\n",
    "                        parts[0] = str(class_id)\n",
    "                        merged_labels.append(\" \".join(parts))\n",
    "            \n",
    "            # Write merged label file\n",
    "            dest_txt = output_labels / f\"{stem}.txt\"\n",
    "            dest_txt.write_text(\"\\n\".join(merged_labels))\n",
    "            copied_count += 1\n",
    "    \n",
    "    print(f\"‚úÖ Copied {copied_count} image-label pairs\")\n",
    "    return copied_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212e6700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üì¶ COPYING YAHOO_HUMAN_BALLS DATASET\n",
      "============================================================\n",
      "üìÅ Found 495 images\n",
      "  - red ball (0): 456 label files\n",
      "  - human (1): 457 label files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 495/495 [00:01<00:00, 374.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Copied 495 image-label pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ COPYING YAHOO_HUMAN_BALLS DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "yahoo_count = copy_dataset_with_class_conversion(\n",
    "    YAHOO_DATASET,\n",
    "    OUTPUT_IMAGES,\n",
    "    OUTPUT_LABELS,\n",
    "    CLASS_MAPPING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de89849",
   "metadata": {},
   "source": [
    "## Step 5: Add COCO Persons\n",
    "\n",
    "Copy COCO person images and labels (class ID = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4534bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_coco_persons(coco_dir: Path, output_images: Path, output_labels: Path, max_images: int = None):\n",
    "    \"\"\"\n",
    "    Copy COCO person dataset (old format with images/ and labels/ directly)\n",
    "    \"\"\"\n",
    "    coco_images = coco_dir / \"images\"\n",
    "    coco_labels = coco_dir / \"labels\"\n",
    "    \n",
    "    if not coco_images.exists() or not coco_labels.exists():\n",
    "        print(f\"‚ö†Ô∏è  COCO dataset not found at {coco_dir}\")\n",
    "        return 0\n",
    "    \n",
    "    # Get image-label pairs\n",
    "    images = list(coco_images.glob(\"*.jpg\")) + list(coco_images.glob(\"*.jpeg\")) + list(coco_images.glob(\"*.png\"))\n",
    "    \n",
    "    if max_images:\n",
    "        images = random.sample(images, min(len(images), max_images))\n",
    "    \n",
    "    print(f\"üìÅ Found {len(images)} COCO images\")\n",
    "    \n",
    "    copied_count = 0\n",
    "    \n",
    "    for img_path in tqdm(images, desc=\"Copying COCO\"):\n",
    "        stem = img_path.stem\n",
    "        txt_path = coco_labels / f\"{stem}.txt\"\n",
    "        \n",
    "        if not txt_path.exists():\n",
    "            continue\n",
    "        \n",
    "        # Copy image\n",
    "        dest_img = output_images / f\"coco_{img_path.name}\"  # Prefix to avoid conflicts\n",
    "        if not dest_img.exists():\n",
    "            shutil.copy(img_path, dest_img)\n",
    "        \n",
    "        # Copy label (already in class ID 1 format for persons)\n",
    "        dest_txt = output_labels / f\"coco_{stem}.txt\"\n",
    "        if not dest_txt.exists():\n",
    "            shutil.copy(txt_path, dest_txt)\n",
    "            copied_count += 1\n",
    "    \n",
    "    print(f\"‚úÖ Copied {copied_count} COCO image-label pairs\")\n",
    "    return copied_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06271356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üì¶ ADDING COCO PERSONS\n",
      "============================================================\n",
      "üìÅ Found 200 COCO images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying COCO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:00<00:00, 663.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Copied 200 COCO image-label pairs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ ADDING COCO PERSONS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "coco_count = copy_coco_persons(\n",
    "    COCO_DATASET,\n",
    "    OUTPUT_IMAGES,\n",
    "    OUTPUT_LABELS,\n",
    "    max_images=500  # Limit COCO images to balance dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effe9ae",
   "metadata": {},
   "source": [
    "## Step 6: Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95526627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä FINAL DATASET STATISTICS\n",
      "============================================================\n",
      "Total images: 695\n",
      "Total labels: 695\n",
      "\n",
      "Instances per class:\n",
      "  0 (red ball): 461 instances\n",
      "  1 (human): 1277 instances\n",
      "\n",
      "‚úÖ Combined dataset ready at: datasets/ready/combined_train\n",
      "  - Images: datasets/ready/combined_train/images\n",
      "  - Labels: datasets/ready/combined_train/labels\n"
     ]
    }
   ],
   "source": [
    "# Count final dataset\n",
    "total_images = len(list(OUTPUT_IMAGES.glob(\"*\")))\n",
    "total_labels = len(list(OUTPUT_LABELS.glob(\"*.txt\")))\n",
    "\n",
    "# Count instances per class\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "for txt_file in OUTPUT_LABELS.glob(\"*.txt\"):\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                class_id = int(line.split()[0])\n",
    "                class_counts[class_id] += 1\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä FINAL DATASET STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Total labels: {total_labels}\")\n",
    "print(f\"\\nInstances per class:\")\n",
    "for class_id in sorted(class_counts.keys()):\n",
    "    class_name = CLASS_NAMES[class_id]\n",
    "    print(f\"  {class_id} ({class_name}): {class_counts[class_id]} instances\")\n",
    "\n",
    "print(f\"\\n‚úÖ Combined dataset ready at: {OUTPUT_DATASET}\")\n",
    "print(f\"  - Images: {OUTPUT_IMAGES}\")\n",
    "print(f\"  - Labels: {OUTPUT_LABELS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
