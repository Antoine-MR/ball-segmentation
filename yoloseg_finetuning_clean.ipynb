{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c67a2244",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "import subprocess\n",
    "import sys\n",
    "import urllib.request\n",
    "import zipfile\n",
    "\n",
    "from ultralytics.models import YOLO\n",
    "import torch\n",
    "from IPython.display import Image as IPImage, display\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "955feb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "GPU: NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "CUDA: 12.8\n"
     ]
    }
   ],
   "source": [
    "TXT_PATH = Path(\"txt_output_folder\")\n",
    "IMG_PATH = Path(\"balls\")\n",
    "DATASET_ROOT = Path(\"yolo_dataset\")\n",
    "COCO_DIR = Path(\"coco_persons\")\n",
    "COMBINED_DATASET = Path(\"yolo_dataset_combined\")\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "NUM_PERSON_IMAGES = 200\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820cf28",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Ball Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d5e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'val']:\n",
    "    (DATASET_ROOT / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (DATASET_ROOT / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "txt_files = list(TXT_PATH.glob(\"*.txt\"))\n",
    "data_pairs = []\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    stem = txt_file.stem\n",
    "    img_file = None\n",
    "    for ext in ['.jpg', '.jpeg', '.JPG', '.JPEG', '.png', '.PNG']:\n",
    "        candidate = IMG_PATH / f\"{stem}{ext}\"\n",
    "        if candidate.exists():\n",
    "            img_file = candidate\n",
    "            break\n",
    "    if img_file:\n",
    "        data_pairs.append((img_file, txt_file))\n",
    "\n",
    "random.shuffle(data_pairs)\n",
    "split_idx = int(len(data_pairs) * TRAIN_RATIO)\n",
    "train_pairs = data_pairs[:split_idx]\n",
    "val_pairs = data_pairs[split_idx:]\n",
    "\n",
    "for img_file, txt_file in train_pairs:\n",
    "    shutil.copy(img_file, DATASET_ROOT / \"train\" / \"images\" / img_file.name)\n",
    "    shutil.copy(txt_file, DATASET_ROOT / \"train\" / \"labels\" / txt_file.name)\n",
    "\n",
    "for img_file, txt_file in val_pairs:\n",
    "    shutil.copy(img_file, DATASET_ROOT / \"val\" / \"images\" / img_file.name)\n",
    "    shutil.copy(txt_file, DATASET_ROOT / \"val\" / \"labels\" / txt_file.name)\n",
    "\n",
    "print(f\"Ball dataset: train={len(train_pairs)}, val={len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b256a097",
   "metadata": {},
   "source": [
    "## Step 2: Download COCO Person Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6368d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e357210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_DIR.mkdir(exist_ok=True)\n",
    "annotations_url = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "annotations_zip = COCO_DIR / \"annotations_trainval2017.zip\"\n",
    "annotations_dir = COCO_DIR / \"annotations\"\n",
    "\n",
    "if not annotations_dir.exists():\n",
    "    print(\"Downloading COCO annotations...\")\n",
    "    urllib.request.urlretrieve(annotations_url, annotations_zip)\n",
    "    \n",
    "    with zipfile.ZipFile(annotations_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(COCO_DIR)\n",
    "    print(\"Extraction complete\")\n",
    "\n",
    "annFile = annotations_dir / 'instances_train2017.json'\n",
    "coco = COCO(str(annFile))\n",
    "person_cat_id = 1\n",
    "\n",
    "print(f\"COCO annotations loaded (person category: {person_cat_id})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = COCO_DIR / \"images\"\n",
    "labels_dir = COCO_DIR / \"labels\"\n",
    "images_dir.mkdir(exist_ok=True)\n",
    "labels_dir.mkdir(exist_ok=True)\n",
    "\n",
    "img_ids = coco.getImgIds(catIds=[person_cat_id])[:NUM_PERSON_IMAGES]\n",
    "imgs = coco.loadImgs(img_ids)\n",
    "\n",
    "print(f\"Selected {len(imgs)} COCO images with persons\")\n",
    "\n",
    "def coco_segmentation_to_yolo(segmentation: list, img_width: int, img_height: int) -> list[float] | None:\n",
    "    if isinstance(segmentation, list) and len(segmentation) > 0:\n",
    "        polygon = segmentation[0]\n",
    "        points = []\n",
    "        for i in range(0, len(polygon), 2):\n",
    "            x = polygon[i] / img_width\n",
    "            y = polygon[i+1] / img_height\n",
    "            points.extend([x, y])\n",
    "        return points\n",
    "    return None\n",
    "\n",
    "downloaded = 0\n",
    "for img_info in tqdm(imgs, desc=\"Processing\"):\n",
    "    img_id = img_info['id']\n",
    "    img_filename = img_info['file_name']\n",
    "    img_path = images_dir / img_filename\n",
    "    \n",
    "    if not img_path.exists():\n",
    "        try:\n",
    "            urllib.request.urlretrieve(img_info['coco_url'], img_path)\n",
    "            downloaded += 1\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=[person_cat_id], iscrowd=0)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "    \n",
    "    label_path = labels_dir / (img_path.stem + '.txt')\n",
    "    with open(label_path, 'w') as f:\n",
    "        for ann in anns:\n",
    "            if 'segmentation' in ann and ann['segmentation']:\n",
    "                points = coco_segmentation_to_yolo(\n",
    "                    ann['segmentation'], \n",
    "                    img_info['width'], \n",
    "                    img_info['height']\n",
    "                )\n",
    "                if points:\n",
    "                    line = \"1 \" + \" \".join([f\"{p:.6f}\" for p in points])\n",
    "                    f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"Downloaded {downloaded} new images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c319540f",
   "metadata": {},
   "source": [
    "## Step 3: Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7f5e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['train', 'val']:\n",
    "    (COMBINED_DATASET / split / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (COMBINED_DATASET / split / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for split in ['train', 'val']:\n",
    "    src_imgs = DATASET_ROOT / split / \"images\"\n",
    "    src_labels = DATASET_ROOT / split / \"labels\"\n",
    "    dst_imgs = COMBINED_DATASET / split / \"images\"\n",
    "    dst_labels = COMBINED_DATASET / split / \"labels\"\n",
    "    \n",
    "    for img_file in src_imgs.glob(\"*.jpg\"):\n",
    "        shutil.copy(img_file, dst_imgs / img_file.name)\n",
    "        label_file = src_labels / (img_file.stem + '.txt')\n",
    "        if label_file.exists():\n",
    "            shutil.copy(label_file, dst_labels / label_file.name)\n",
    "\n",
    "coco_images = list(images_dir.glob(\"*.jpg\"))\n",
    "random.shuffle(coco_images)\n",
    "\n",
    "split_idx = int(len(coco_images) * 0.8)\n",
    "train_coco = coco_images[:split_idx]\n",
    "val_coco = coco_images[split_idx:]\n",
    "\n",
    "for img_file in train_coco:\n",
    "    shutil.copy(img_file, COMBINED_DATASET / \"train\" / \"images\" / img_file.name)\n",
    "    label_file = labels_dir / (img_file.stem + '.txt')\n",
    "    if label_file.exists():\n",
    "        shutil.copy(label_file, COMBINED_DATASET / \"train\" / \"labels\" / label_file.name)\n",
    "\n",
    "for img_file in val_coco:\n",
    "    shutil.copy(img_file, COMBINED_DATASET / \"val\" / \"images\" / img_file.name)\n",
    "    label_file = labels_dir / (img_file.stem + '.txt')\n",
    "    if label_file.exists():\n",
    "        shutil.copy(label_file, COMBINED_DATASET / \"val\" / \"labels\" / label_file.name)\n",
    "\n",
    "yaml_data = {\n",
    "    'path': str(COMBINED_DATASET.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'nc': 2,\n",
    "    'names': {0: 'ball', 1: 'person'}\n",
    "}\n",
    "\n",
    "yaml_path = COMBINED_DATASET / 'data.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "train_total = len(list((COMBINED_DATASET / 'train' / 'images').glob('*.jpg')))\n",
    "val_total = len(list((COMBINED_DATASET / 'val' / 'images').glob('*.jpg')))\n",
    "print(f\"Combined dataset: train={train_total}, val={val_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efabb50",
   "metadata": {},
   "source": [
    "## Step 4: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e79322af",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = \"ball_person_model_head_only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n-seg.pt')\n",
    "\n",
    "head_idx = next((i for i, m in enumerate(model.model.model) if 'Detect' in m.__class__.__name__ or 'Segment' in m.__class__.__name__), len(model.model.model) - 1)\n",
    "print(f\"Head starts at layer: {head_idx}\")\n",
    "print(f\"Freezing layers: 0-{head_idx-1}\")\n",
    "\n",
    "results = model.train(\n",
    "    data=str(yaml_path),\n",
    "    freeze=list(range(head_idx)),\n",
    "    epochs=10,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    device=DEVICE,\n",
    "    project='runs/segment',\n",
    "    name=project_name,\n",
    "    exist_ok=True,\n",
    "    pretrained=True,\n",
    "    optimizer='Adam',\n",
    "    lr0=0.001,\n",
    "    patience=15,\n",
    "    save=True,\n",
    "    save_period=5,\n",
    "    plots=True,\n",
    "    workers=0,\n",
    "    val=False,\n",
    "    hsv_h=0.01,\n",
    "    hsv_s=0.5,\n",
    "    hsv_v=0.3,\n",
    "    degrees=5.0,\n",
    "    translate=0.1,\n",
    "    scale=0.3,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.5,\n",
    "    mosaic=0.5\n",
    ")\n",
    "\n",
    "print(f\"Model saved: runs/segment/ball_person_model/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f11eea",
   "metadata": {},
   "source": [
    "## Step 5: Load Trained Model\n",
    "\n",
    "Execute this cell to load the trained model (without retraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "800e96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path('runs/segment') / project_name / \"weights\"/ \"best.pt\"\n",
    "\n",
    "model = YOLO(str(model_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d48add",
   "metadata": {},
   "source": [
    "## Step 6: Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d50c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.val(\n",
    "    data=str(yaml_path),\n",
    "    batch=8,\n",
    "    workers=0,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "print(f\"Box - mAP50: {metrics.box.map50:.4f}, mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Mask - mAP50: {metrics.seg.map50:.4f}, mAP50-95: {metrics.seg.map:.4f}\")\n",
    "\n",
    "for i, name in enumerate(['ball', 'person']):\n",
    "    if i < len(metrics.seg.ap50):\n",
    "        print(f\"{name}: mAP50={metrics.seg.ap50[i]:.4f}, mAP50-95={metrics.seg.ap[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = Path('runs/segment/ball_person_model')\n",
    "\n",
    "if results_dir.exists():\n",
    "    plots = ['results.png', 'confusion_matrix.png', 'val_batch0_labels.jpg', 'val_batch0_pred.jpg']\n",
    "    \n",
    "    for plot in plots:\n",
    "        plot_path = results_dir / plot\n",
    "        if plot_path.exists():\n",
    "            print(f\"{plot}:\")\n",
    "            display(IPImage(filename=str(plot_path), width=800))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509959d8",
   "metadata": {},
   "source": [
    "## Test on Manual Validation Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb3ea09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05cfe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def exec_model(img_path: Path, imgsz: int = 255, show=True, show_original_size=False):\n",
    "    test_manual_img = img_path\n",
    "    \n",
    "    start = perf_counter()\n",
    "    results = model.predict(\n",
    "        source=str(test_manual_img),\n",
    "        save=True,\n",
    "        conf=0.25,\n",
    "        iou=0.5,\n",
    "        imgsz=imgsz,\n",
    "        device=DEVICE,\n",
    "        show_labels=True,\n",
    "        show_conf=True,\n",
    "        project='runs/segment',\n",
    "        name='manual_validation_pred',\n",
    "        exist_ok=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    for r in results:\n",
    "        if r.boxes is not None and len(r.boxes) > 0:\n",
    "            ball_count = sum(1 for cls in r.boxes.cls if int(cls) == 0)\n",
    "            person_count = sum(1 for cls in r.boxes.cls if int(cls) == 1)\n",
    "            \n",
    "            print(f\"Detected: {ball_count} ball(s), {person_count} person(s)\")\n",
    "            \n",
    "            for i, (box, cls) in enumerate(zip(r.boxes.xyxy, r.boxes.cls)):\n",
    "                class_name = 'ball' if int(cls) == 0 else 'person'\n",
    "                conf = r.boxes.conf[i]\n",
    "                print(f\"  {class_name}: {conf:.3f}\")\n",
    "            \n",
    "            pred_path = Path('runs/segment/manual_validation_pred') / test_manual_img.name\n",
    "            if pred_path.exists() and show:\n",
    "                width = None if show_original_size else imgsz\n",
    "                display(IPImage(filename=str(pred_path), width=width))\n",
    "        else:\n",
    "            print(\"No detections\")\n",
    "        \n",
    "    return perf_counter() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b4b530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(source: Path | list[Path], imgsz: int = 640, runs_per_image: int = 10, warmup_runs: int = 3, use_cpu: bool = False):\n",
    "    \"\"\"\n",
    "    Measure pure inference time without save/display overhead\n",
    "    \n",
    "    Args:\n",
    "        source: Path to folder, single image, or list of image paths\n",
    "        imgsz: Input image size\n",
    "        runs_per_image: Number of runs per image\n",
    "        warmup_runs: Number of warmup runs on first image\n",
    "        use_cpu: Use CPU instead of GPU\n",
    "    \"\"\"\n",
    "    device = 'cpu' if use_cpu else DEVICE\n",
    "    \n",
    "    if isinstance(source, Path):\n",
    "        if source.is_dir():\n",
    "            img_paths = list(source.glob(\"*.jpg\")) + list(source.glob(\"*.png\"))\n",
    "        else:\n",
    "            img_paths = [source]\n",
    "    else:\n",
    "        img_paths = source\n",
    "    \n",
    "    device_name = \"CPU\" if use_cpu else f\"GPU ({torch.cuda.get_device_name(0)})\"\n",
    "    print(f\"Warming up {device_name} ({warmup_runs} runs)...\")\n",
    "    for _ in range(warmup_runs):\n",
    "        model.predict(source=str(img_paths[0]), imgsz=imgsz, device=device, save=False, verbose=False)\n",
    "    \n",
    "    print(f\"Benchmarking {len(img_paths)} images ({runs_per_image} runs each) on {device_name}...\")\n",
    "    all_averages = []\n",
    "    \n",
    "    for img_path in tqdm(img_paths):\n",
    "        times = []\n",
    "        for _ in range(runs_per_image):\n",
    "            start = perf_counter()\n",
    "            model.predict(source=str(img_path), imgsz=imgsz, device=device, save=False, verbose=False)\n",
    "            times.append(perf_counter() - start)\n",
    "        \n",
    "        avg_time = sum(times) / len(times)\n",
    "        all_averages.append(avg_time)\n",
    "    \n",
    "    global_avg = sum(all_averages) / len(all_averages)\n",
    "    global_min = min(all_averages)\n",
    "    global_max = max(all_averages)\n",
    "    \n",
    "    mean_diff_sq = sum((t - global_avg) ** 2 for t in all_averages) / len(all_averages)\n",
    "    global_std = mean_diff_sq ** 0.5\n",
    "    \n",
    "    print(f\"\\nGlobal inference time (imgsz={imgsz}, device={device}):\")\n",
    "    print(f\"  Average: {global_avg*1000:.2f}ms\")\n",
    "    print(f\"  Min: {global_min*1000:.2f}ms\")\n",
    "    print(f\"  Max: {global_max*1000:.2f}ms\")\n",
    "    print(f\"  Std: {global_std*1000:.2f}ms\")\n",
    "    print(f\"  FPS: {1/global_avg:.1f}\")\n",
    "    \n",
    "    return global_avg, global_min, global_max, global_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9b3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = list(Path(\"df\").glob(\"*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71159bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warming up CPU (3 runs)...\n",
      "Benchmarking 17 images (10 runs each) on CPU...\n",
      "Benchmarking 17 images (10 runs each) on CPU...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:25<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global inference time (imgsz=128, device=cpu):\n",
      "  Average: 151.09ms\n",
      "  Min: 71.87ms\n",
      "  Max: 182.51ms\n",
      "  Std: 25.74ms\n",
      "  FPS: 6.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.15108706029425187,\n",
       " 0.0718685510000796,\n",
       " 0.18250563020010305,\n",
       " 0.025742845018418788)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_inference(img_paths, imgsz=128, use_cpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3150a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = sum(exec_times) / len(exec_times)\n",
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_model(Path(\"df\")/ \"valid.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
