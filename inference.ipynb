{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bed8fab7",
   "metadata": {},
   "source": [
    "# Ball Segmentation - Inference Demo\n",
    "\n",
    "This notebook demonstrates how to use trained models for inference on new images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39725c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from time import perf_counter\n",
    "import torch\n",
    "from ultralytics.models import YOLO\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import Image as IPImage, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DisplayPath\n",
    "Path = DisplayPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca93af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = Path('datasets/ready/full_dataset/demo_folder')\n",
    "assert img_dir.exists(), f\"Directory {img_dir} does not exist.\"\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d3b90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS_DIR = Path(\"runs/segment\")\n",
    "project_name = 'ball_person_trashcan_model_v4'\n",
    "best_model_path = RUNS_DIR / project_name / 'weights' / 'best.pt'\n",
    "best_model_path.display()\n",
    "model = YOLO(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d394a371",
   "metadata": {},
   "source": [
    "## Run Inference on Single Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14482eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = img_dir / \"tom3.jpg\"\n",
    "\n",
    "def predict(img_path: Path, conf=0.2):\n",
    "    start_time = perf_counter()\n",
    "    \n",
    "    results = model.predict(\n",
    "        source=str(img_path),\n",
    "        save=False,\n",
    "        conf=conf,\n",
    "        iou=0.5,\n",
    "        imgsz=640,\n",
    "        device=DEVICE,\n",
    "        show_labels=True,\n",
    "        show_conf=True\n",
    "    )\n",
    "    end_time = perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Inference time: {elapsed_time:.4f} seconds\")\n",
    "    \n",
    "    # Plot and display the results\n",
    "    if results:\n",
    "        annotated_img = results[0].plot()\n",
    "        annotated_img = Image.fromarray(annotated_img[..., ::-1])  # BGR to RGB\n",
    "        display(annotated_img)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c742e875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img(img_path: Path) -> Path:\n",
    "    # augment red color: ISOLATE red - make red pixels pop, desaturate everything else\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_array = np.array(img, dtype=np.float32)\n",
    "    \n",
    "    red_channel = img_array[:, :, 0]\n",
    "    green_channel = img_array[:, :, 1]\n",
    "    blue_channel = img_array[:, :, 2]\n",
    "    \n",
    "    # Calculate \"redness\" intensity\n",
    "    # Positive if Red is dominant, negative otherwise\n",
    "    # We compare Red to the MAXIMUM of Green and Blue\n",
    "    dominance = red_channel - np.maximum(green_channel, blue_channel)\n",
    "    \n",
    "    # Create a soft mask (0.0 to 1.0) based on dominance\n",
    "    # Shift sigmoid center to require some minimum redness (e.g. 15)\n",
    "    # Steepness divisor determines how sharp the cutoff is\n",
    "    mask = 1 / (1 + np.exp(-(dominance - 20) / 10))\n",
    "    \n",
    "    # Create a grayscale version of the image for non-red parts\n",
    "    grayscale = (red_channel + green_channel + blue_channel) / 3.0\n",
    "    \n",
    "    # For the \"Red\" version (when mask is 1):\n",
    "    # Boost Red, suppress Green/Blue to make it very vivid\n",
    "    r_red = np.clip(red_channel * 1.5, 0, 255)\n",
    "    g_red = np.clip(green_channel * 0.2, 0, 255) # Darken G\n",
    "    b_red = np.clip(blue_channel * 0.2, 0, 255) # Darken B\n",
    "    \n",
    "    # Blend Red version and Grayscale version using the mask\n",
    "    final_r = r_red * mask + grayscale * (1 - mask)\n",
    "    final_g = g_red * mask + grayscale * (1 - mask)\n",
    "    final_b = b_red * mask + grayscale * (1 - mask)\n",
    "    \n",
    "    # Stack and save\n",
    "    augmented_img_array = np.stack((final_r, final_g, final_b), axis=-1).astype(np.uint8)\n",
    "    augmented_img = Image.fromarray(augmented_img_array)\n",
    "    augmented_img_path = img_path.parent / f\"augmented_{img_path.name}\"\n",
    "    augmented_img.save(augmented_img_path)\n",
    "    return augmented_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_img_v2(img_path: Path) -> Path:\n",
    "    # Mimic the curve from the screenshot (brightening shadows/midtones on Value channel)\n",
    "    img = Image.open(img_path).convert(\"HSV\")\n",
    "    img_array = np.array(img)\n",
    "    \n",
    "    # H = [:,:,0], S = [:,:,1], V = [:,:,2]\n",
    "    v_channel = img_array[:, :, 2]\n",
    "    \n",
    "    # Control points estimated from the GIMP curve screenshot\n",
    "    # Grid seems to be 4x4, so steps of 64.\n",
    "    # (0,0) -> Bottom left\n",
    "    # (64, 90) -> First vertical line, curve is higher than diagonal (~64)\n",
    "    # (128, 160) -> Mid point, slightly lifted\n",
    "    # (192, 215) -> Third line\n",
    "    # (255, 255) -> Top right\n",
    "    \n",
    "    x_points = [0, 64, 128, 192, 255]\n",
    "    y_points = [0, 90, 160, 215, 255]\n",
    "    \n",
    "    # Create Lookup Table (LUT)\n",
    "    x_val = np.arange(256)\n",
    "    lut = np.interp(x_val, x_points, y_points).astype(np.uint8)\n",
    "    \n",
    "    # Apply LUT to V channel\n",
    "    # Numpy advanced indexing: lut[v_channel] replaces each value in v_channel with lut[value]\n",
    "    v_channel_transformed = lut[v_channel]\n",
    "    \n",
    "    # Update image array\n",
    "    img_array[:, :, 2] = v_channel_transformed\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    new_img = Image.fromarray(img_array, mode=\"HSV\").convert(\"RGB\")\n",
    "    \n",
    "    save_path = img_path.parent / f\"augmented_v2_{img_path.name}\"\n",
    "    new_img.save(save_path)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2abddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(path:=prepare_img_v2(img_dir / \"tom_original.jpg\")).display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3119f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(path, conf=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
