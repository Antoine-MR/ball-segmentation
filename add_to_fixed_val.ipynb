{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbe8080e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(not found): datasets/temp_pipeline_output\n",
      "✓ Removed: datasets/new_val\n",
      "✓ Removed: datasets/preprocessed/fixed_val_preview\n"
     ]
    }
   ],
   "source": [
    "# # Cleanup all output folders created by this notebook\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# # List of folders to remove (add more if needed)\n",
    "folders_to_remove = [\n",
    "    \"datasets/temp_pipeline_output\",\n",
    "    \"datasets/new_val\",\n",
    "    \"datasets/preprocessed/fixed_val_preview\",\n",
    "]\n",
    "\n",
    "for folder in folders_to_remove:\n",
    "    p = Path(folder)\n",
    "    if p.exists():\n",
    "        shutil.rmtree(p)\n",
    "        print(f\"✓ Removed: {folder}\")\n",
    "    else:\n",
    "        print(f\"(not found): {folder}\")\n",
    "        \n",
    "#todo: place this after defined paths later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6ed31",
   "metadata": {},
   "source": [
    "# Add Labeled Images to Fixed Validation (Option B + Purge)\n",
    "\n",
    "Optional notebook to inject **already labeled** images into `datasets/ready/fixed_val`, with:\n",
    "- **Option B**: if filename collides but hash differs, auto-rename with a suffix.\n",
    "- **Dedup by hash**: if hash is identical, skip to avoid duplicates.\n",
    "- **Class check**: only `red ball`, `human`, `trashcan`.\n",
    "- **Human review**: previews generated for visual QA.\n",
    "- **Purge option**: clean outputs/previews before running.\n",
    "- **Previews location**: `datasets/preprocessed/fixed_val_preview`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f1a5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import hashlib\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Project detectors\n",
    "from src.detection import GroundingDINODetector\n",
    "from src.segmentation import SAMSegmenter\n",
    "from src.pipeline import img_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8828f280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayPath(Path):\n",
    "    def display(self):\n",
    "        display(Markdown(f\"[{self}]({self})\") if self.exists() else str(self))\n",
    "Path = DisplayPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea1a4f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/fixed_val](datasets/ready/fixed_val)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROJECT_DIR = Path(\"./datasets/ready/fixed_val\")\n",
    "# PROJECT_DIR = Path(\"datasets/ready/fixed_val\")\n",
    "\n",
    "PROJECT_DIR.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d17dd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/fixed_val](datasets/ready/fixed_val)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/preprocessed/fixed_val_preview](datasets/preprocessed/fixed_val_preview)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/raw/tom_trashcans](datasets/raw/tom_trashcans)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/new_val/images](datasets/new_val/images)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/new_val/labels](datasets/new_val/labels)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/trashcan_pipeline_output](datasets/trashcan_pipeline_output)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Parameters\n",
    "dirs = [\n",
    "    PROJECT_DIR := Path(\"datasets/ready/fixed_val\"),\n",
    "    PREVIEW_DIR := Path(\"datasets/preprocessed/fixed_val_preview\"),\n",
    "    # RAW_SOURCE_DIR = Path(\"datasets/raw/IRL_validation_pictures\"),\n",
    "    RAW_SOURCE_DIR := Path(\"datasets/raw/tom_trashcans\"),     \n",
    "    NEW_IMAGES_DIR := Path(\"datasets/new_val/images\"),      \n",
    "    NEW_LABELS_DIR := Path(\"datasets/new_val/labels\"),\n",
    "    TEMP_PIPELINE_DIR := Path(\"datasets/trashcan_pipeline_output\")   \n",
    "]\n",
    "for dir in dirs:\n",
    "    dir.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ff2bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dont use red ball for trashcan validation there should be none\n",
    "# ALLOWED_CLASSES = {\"red ball\": 0, \"human\": 1} # <-- for irl pictures\n",
    "ALLOWED_CLASSES = {\"human\": 1, \"trashcan\": 2} # <-- for irl trashcans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a1961e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Parameters loaded.\n"
     ]
    }
   ],
   "source": [
    "CLASS_IDS = set(ALLOWED_CLASSES.values())\n",
    "\n",
    "# Detection / segmentation\n",
    "BOX_THRESHOLD = 0.42\n",
    "TEXT_THRESHOLD = 0.2\n",
    "\n",
    "\n",
    "\n",
    "PROMPT = \" . \".join(ALLOWED_CLASSES.keys())\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Options\n",
    "OPTION_B_RENAME_ON_NAME_CONFLICT = True   # rename on filename collision with different hash\n",
    "PURGE_OUTPUTS = True                      # purge previews/output folders before run\n",
    "SAMPLES_PER_SPLIT = 20                    # previews per split\n",
    "\n",
    "random.seed(42)\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(\"Parameters loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b92cc21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Purged preview outputs.\n"
     ]
    }
   ],
   "source": [
    "# Purge existing previews / temp if requested\n",
    "if PURGE_OUTPUTS:\n",
    "    for path in [PREVIEW_DIR]:\n",
    "        if path.exists():\n",
    "            shutil.rmtree(path)\n",
    "    PREVIEW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"✓ Purged preview outputs.\")\n",
    "else:\n",
    "    PREVIEW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(\"Skipping purge (PURGE_OUTPUTS=False)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a5dc8",
   "metadata": {},
   "source": [
    "## Auto-label with GroundingDINO + SAM2\n",
    "This section auto-labels raw images into `NEW_IMAGES_DIR/NEW_LABELS_DIR` before merging into `fixed_val`.\n",
    "\n",
    "- Classes enforced: red ball, human, trashcan\n",
    "- Dedup: skip identical hashes; collision on name => rename (option B)\n",
    "- Outputs stay separate so you can review before copy to fixed val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6b3bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_polygon(mask: np.ndarray) -> list:\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return []\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    epsilon = 0.005 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, epsilon, True)\n",
    "    if len(approx) < 3: \n",
    "        return []\n",
    "    h, w = mask.shape\n",
    "    pts = []\n",
    "    for p in approx:\n",
    "        x, y = p[0]\n",
    "        pts.extend([x / w, y / h])\n",
    "    return pts\n",
    "\n",
    "\n",
    "def save_yolo_label(file_path: Path, labels):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for cls_id, pts in labels:\n",
    "            pts_str = \" \".join(f\"{p:.6f}\" for p in pts)\n",
    "            f.write(f\"{cls_id} {pts_str}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ae783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "try :\n",
    "    detector, segmenter #type: ignore\n",
    "except:\n",
    "    detector = GroundingDINODetector(\n",
    "        box_threshold=BOX_THRESHOLD,\n",
    "        text_threshold=TEXT_THRESHOLD,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "    segmenter = SAMSegmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b4214783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using temporary pipeline dir\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/trashcan_pipeline_output](datasets/trashcan_pipeline_output)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw files found: 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6ca1d5021e4bbca0a6a6a0cba10ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Pipeline:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline finished. Processed: 14, Errors: 0\n",
      "Images to post-process: 13\n"
     ]
    }
   ],
   "source": [
    "# Auto-label using src.pipeline.img_pipeline\n",
    "# This ensures consistency with the main data preparation pipeline (EXIF handling, visualization, etc.)\n",
    "\n",
    "# 1. Setup Temporary Directory for Pipeline Output\n",
    "if TEMP_PIPELINE_DIR.exists():\n",
    "    shutil.rmtree(TEMP_PIPELINE_DIR)\n",
    "\n",
    "TEMP_DET_DIR = TEMP_PIPELINE_DIR / \"detection\"\n",
    "TEMP_SEG_DIR = TEMP_PIPELINE_DIR / \"segmentation\"\n",
    "TEMP_LBL_DIR = TEMP_PIPELINE_DIR / \"labels\"\n",
    "TEMP_IMG_DIR = TEMP_PIPELINE_DIR / \"images\"\n",
    "TEMP_EMPTY_DIR = TEMP_PIPELINE_DIR / \"empty\"\n",
    "\n",
    "for d in [TEMP_DET_DIR, TEMP_SEG_DIR, TEMP_LBL_DIR, TEMP_IMG_DIR, TEMP_EMPTY_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Using temporary pipeline dir\")\n",
    "TEMP_PIPELINE_DIR.display()\n",
    "\n",
    "# 2. Run Pipeline on Raw Images\n",
    "raw_files = [p for p in RAW_SOURCE_DIR.rglob(\"*\") if p.suffix.lower() not in ['.Identifier']]\n",
    "print(f\"Raw files found: {len(raw_files)}\")\n",
    "\n",
    "processed_count = 0\n",
    "errors = 0\n",
    "\n",
    "for img_path in tqdm(raw_files, desc=\"Running Pipeline\"):\n",
    "    if not img_path.is_file():\n",
    "        continue\n",
    "    try:\n",
    "        img_pipeline(\n",
    "            img_path=img_path,\n",
    "            detect_fn=lambda p: detector.detect(p, text_prompt=PROMPT, return_all_by_label=True),\n",
    "            segment_fn=segmenter.segment_bbox,\n",
    "            det_output_dir=TEMP_DET_DIR,\n",
    "            seg_output_dir=TEMP_SEG_DIR,\n",
    "            txt_output_dir=TEMP_LBL_DIR,\n",
    "            empty_dir=TEMP_EMPTY_DIR,\n",
    "            images_output_dir=TEMP_IMG_DIR\n",
    "        )\n",
    "        processed_count += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Pipeline error on {img_path.name}: {e}\")\n",
    "        errors += 1\n",
    "\n",
    "print(f\"Pipeline finished. Processed: {processed_count}, Errors: {errors}\")\n",
    "\n",
    "# 3. Post-process: Hash, Merge Labels, and Move to Final Destination\n",
    "NEW_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "NEW_LABELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed_hashes = set()\n",
    "added_final = 0\n",
    "skipped_dup = 0\n",
    "\n",
    "# Iterate over the images successfully processed by the pipeline\n",
    "# Note: img_pipeline copies original images to TEMP_IMG_DIR\n",
    "pipeline_images = list(TEMP_IMG_DIR.glob(\"*\"))\n",
    "print(f\"Images to post-process: {len(pipeline_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1abda4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cad2b43ab91428d92b50e2a1b559943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging & Hashing:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Import Stats: Added 13, Skipped Dup 0\n"
     ]
    }
   ],
   "source": [
    "processed_hashes = set()\n",
    "\n",
    "for img_path in tqdm(pipeline_images, desc=\"Merging & Hashing\"):\n",
    "\n",
    "    # Open and Fix EXIF (Critical: Pipeline generated polygons on the fixed image)\n",
    "    pil_img = Image.open(img_path)\n",
    "    pil_img = ImageOps.exif_transpose(pil_img)\n",
    "    if pil_img.mode != 'RGB':\n",
    "        pil_img = pil_img.convert('RGB')\n",
    "    \n",
    "    # Calculate Hash\n",
    "    hsh = hashlib.md5(pil_img.tobytes()).hexdigest()\n",
    "    \n",
    "    if hsh in processed_hashes:\n",
    "        skipped_dup += 1\n",
    "        continue\n",
    "        \n",
    "    # Collect Labels from subfolders\n",
    "    # Pipeline outputs: TEMP_LBL_DIR / class_name / filename.txt\n",
    "    # We need to merge them into one file with correct class IDs\n",
    "    \n",
    "    final_labels = []\n",
    "    has_labels = False\n",
    "    \n",
    "    for class_name, class_id in ALLOWED_CLASSES.items():\n",
    "        # The pipeline uses the class name as folder name\n",
    "        lbl_file = TEMP_LBL_DIR / class_name / f\"{img_path.stem}.txt\"\n",
    "        \n",
    "        if lbl_file.exists():\n",
    "            # Read polygons\n",
    "            content = lbl_file.read_text().strip()\n",
    "            if content:\n",
    "                lines = content.split('\\n')\n",
    "                for line in lines:\n",
    "                    parts = line.strip().split()\n",
    "                    if len(parts) > 1:\n",
    "                        # Replace the first '0' with the actual class_id\n",
    "                        # Pipeline outputs \"0 x y ...\", we want \"class_id x y ...\"\n",
    "                        coords = parts[1:]\n",
    "                        final_labels.append(f\"{class_id} \" + \" \".join(coords))\n",
    "                        has_labels = True\n",
    "    \n",
    "    if not has_labels:\n",
    "        # Should not happen if image is in TEMP_IMG_DIR (pipeline puts empty ones in empty_dir)\n",
    "        # But check just in case\n",
    "        continue\n",
    "        \n",
    "    # Save Final Image (Transposed)\n",
    "    target_img_name = f\"{hsh}.jpg\"\n",
    "    target_lbl_name = f\"{hsh}.txt\"\n",
    "    \n",
    "    pil_img.save(NEW_IMAGES_DIR / target_img_name, quality=95)\n",
    "    \n",
    "    with open(NEW_LABELS_DIR / target_lbl_name, 'w') as f:\n",
    "        f.write(\"\\n\".join(final_labels))\n",
    "        \n",
    "    processed_hashes.add(hsh)\n",
    "    added_final += 1\n",
    "    \n",
    "\n",
    "\n",
    "print(f\"Final Import Stats: Added {added_final}, Skipped Dup {skipped_dup}\")\n",
    "\n",
    "# Optional: Clean up temp\n",
    "# shutil.rmtree(TEMP_PIPELINE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b373ffe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[datasets/new_val/images](datasets/new_val/images)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, 'Auto-labeled images')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEW_IMAGES_DIR.display(), \"Auto-labeled images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "243f29a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping conversion (CONVERT=False)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_jpg(source_folder: Path, output_folder: Path):\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.bmp', '.gif', '.tiff', '.svg', '.heic', '.HEIC'}\n",
    "    converted = 0\n",
    "    errors = 0\n",
    "    for file_path in tqdm(list(source_folder.rglob(\"*\")), desc=\"Convert to JPG\"):\n",
    "        if ':Zone.Identifier' in str(file_path) or not file_path.is_file():\n",
    "            continue\n",
    "        if file_path.suffix.lower() not in image_extensions:\n",
    "            continue\n",
    "        rel = file_path.relative_to(source_folder)\n",
    "        out_path = output_folder / rel.parent / (file_path.stem + '.jpg')\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                # ALIGN WITH PIPELINE.PY: Always call exif_transpose directly\n",
    "                img = ImageOps.exif_transpose(img)\n",
    "                \n",
    "                if img.mode in ('RGBA', 'LA', 'P'):\n",
    "                    bg = Image.new('RGB', img.size, (255, 255, 255))\n",
    "                    if img.mode == 'P':\n",
    "                        img = img.convert('RGBA')\n",
    "                    bg.paste(img, mask=img.split()[-1] if img.mode in ('RGBA', 'LA') else None)\n",
    "                    img = bg\n",
    "                elif img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                img.save(out_path, 'JPEG', quality=95)\n",
    "                converted += 1\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            print(f\"✗ {file_path.name}: {e}\")\n",
    "    print(f\"Converted: {converted}, Errors: {errors}, Output: {output_folder}\")\n",
    "    return output_folder\n",
    "\n",
    "CONVERT = False\n",
    "CONVERTED_DIR = NEW_IMAGES_DIR.parent / (NEW_IMAGES_DIR.name + \"_jpg\")\n",
    "\n",
    "if CONVERT:\n",
    "    print(f\"Converting {NEW_IMAGES_DIR} -> {CONVERTED_DIR}\")\n",
    "    NEW_IMAGES_DIR = convert_to_jpg(NEW_IMAGES_DIR, CONVERTED_DIR)\n",
    "else:\n",
    "    print(\"Skipping conversion (CONVERT=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "91a13f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing fixed_val images: 47\n"
     ]
    }
   ],
   "source": [
    "def md5_hash(p: Path) -> str:\n",
    "    h = hashlib.md5()\n",
    "    with open(p, 'rb') as f:\n",
    "        h.update(f.read())\n",
    "    return h.hexdigest()\n",
    "\n",
    "# Load existing hashes in fixed_val\n",
    "existing_hashes = {}\n",
    "PROJECT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "(PROJECT_DIR / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "(PROJECT_DIR / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for img_path in (PROJECT_DIR / \"images\").glob(\"*\"):\n",
    "    if img_path.suffix.lower() not in ['.jpg', '.jpeg', '.png']:\n",
    "        continue\n",
    "    existing_hashes[md5_hash(img_path)] = img_path.name\n",
    "\n",
    "print(f\"Existing fixed_val images: {len(existing_hashes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e048985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e355834bb94a03a5dcd001fdf87495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Add to fixed_val:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 0, Renamed: 0, Skipped dup hash: 13, Errors: 0\n",
      "to \n"
     ]
    }
   ],
   "source": [
    "# Validate inputs\n",
    "if not NEW_IMAGES_DIR.exists():\n",
    "    raise FileNotFoundError(f\"NEW_IMAGES_DIR missing: {NEW_IMAGES_DIR}\")\n",
    "if not NEW_LABELS_DIR.exists():\n",
    "    raise FileNotFoundError(f\"NEW_LABELS_DIR missing: {NEW_LABELS_DIR}\")\n",
    "\n",
    "added = 0\n",
    "skipped_dupe = 0\n",
    "renamed = 0\n",
    "errors = 0\n",
    "\n",
    "for img_path in tqdm(list(NEW_IMAGES_DIR.rglob(\"*\")), desc=\"Add to fixed_val\"):\n",
    "    if not img_path.is_file():\n",
    "        continue\n",
    "    if img_path.suffix.lower() not in ['.jpg', '.jpeg', '.png']:\n",
    "        continue\n",
    "\n",
    "    stem = img_path.stem\n",
    "    lbl_path = NEW_LABELS_DIR / f\"{stem}.txt\"\n",
    "    if not lbl_path.exists():\n",
    "        print(f\"✗ Missing label for {img_path}\")\n",
    "        errors += 1\n",
    "        continue\n",
    "\n",
    "    # validate label\n",
    "    valid = True\n",
    "    lines_out = []\n",
    "    with open(lbl_path) as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 3 or len(parts[1:]) % 2 != 0:\n",
    "                valid = False\n",
    "                break\n",
    "            cls_id = int(float(parts[0]))\n",
    "            if cls_id not in CLASS_IDS:\n",
    "                valid = False\n",
    "                break\n",
    "            lines_out.append(line.strip())\n",
    "    if not valid:\n",
    "        print(f\"✗ Invalid label format/classes: {lbl_path}\")\n",
    "        errors += 1\n",
    "        continue\n",
    "\n",
    "    file_hash = md5_hash(img_path)\n",
    "    if file_hash in existing_hashes:\n",
    "        skipped_dupe += 1\n",
    "        continue\n",
    "\n",
    "    target_name = img_path.name\n",
    "    target_img = PROJECT_DIR / \"images\" / target_name\n",
    "    target_lbl = PROJECT_DIR / \"labels\" / f\"{Path(target_name).stem}.txt\"\n",
    "\n",
    "    if target_img.exists() and OPTION_B_RENAME_ON_NAME_CONFLICT:\n",
    "        # rename with suffix\n",
    "        suffix = 1\n",
    "        while True:\n",
    "            candidate = PROJECT_DIR / \"images\" / f\"{Path(target_name).stem}_v{suffix}{img_path.suffix}\"\n",
    "            if not candidate.exists():\n",
    "                target_img = candidate\n",
    "                target_lbl = PROJECT_DIR / \"labels\" / f\"{candidate.stem}.txt\"\n",
    "                renamed += 1\n",
    "                break\n",
    "            suffix += 1\n",
    "\n",
    "    # copy\n",
    "    shutil.copy(img_path, target_img)\n",
    "    with open(target_lbl, 'w') as f:\n",
    "        for line in lines_out:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "    existing_hashes[file_hash] = target_img.name\n",
    "    added += 1\n",
    "\n",
    "print(f\"Added: {added}, Renamed: {renamed}, Skipped dup hash: {skipped_dupe}, Errors: {errors}\")\n",
    "print(\"to \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14d2fb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d597e87d80f844129e557a460937467c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing 13 samples from NEW auto-labeled images (not existing fixed_val)\n",
      "Previews written to\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/preprocessed/fixed_val_preview](datasets/preprocessed/fixed_val_preview)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate previews for human QA\n",
    "COLORS = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]  # BGR\n",
    "PREVIEW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def draw_yolo_polygons(img_path: Path, lbl_path: Path, out_path: Path):\n",
    "    if not img_path.exists():\n",
    "        return False\n",
    "    \n",
    "    # Use PIL to ensure EXIF rotation is applied, matching the pipeline's behavior\n",
    "    try:\n",
    "        with Image.open(img_path) as pil_img:\n",
    "            pil_img = ImageOps.exif_transpose(pil_img)\n",
    "            if pil_img.mode != 'RGB':\n",
    "                pil_img = pil_img.convert('RGB')\n",
    "            # Convert to OpenCV format (BGR)\n",
    "            img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {img_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    if lbl_path.exists():\n",
    "        with open(lbl_path) as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) < 3:\n",
    "                    continue\n",
    "                cls_id = int(float(parts[0]))\n",
    "                coords = [float(p) for p in parts[1:]]\n",
    "                pts = []\n",
    "                for i in range(0, len(coords), 2):\n",
    "                    x = int(coords[i] * w)\n",
    "                    y = int(coords[i+1] * h)\n",
    "                    pts.append([x, y])\n",
    "                if len(pts) < 3:\n",
    "                    continue\n",
    "                poly = np.array(pts, np.int32).reshape((-1, 1, 2))\n",
    "                color = COLORS[cls_id % len(COLORS)]\n",
    "                cv2.polylines(img, [poly], True, color, 2)\n",
    "                cv2.putText(img, f\"cls {cls_id}\", (pts[0][0], pts[0][1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    cv2.imwrite(str(out_path), img)\n",
    "    return True\n",
    "\n",
    "# Create previews from NEW auto-labeled images (not fixed_val which contains old data)\n",
    "imgs = list(NEW_IMAGES_DIR.glob(\"*.jpg\")) + list(NEW_IMAGES_DIR.glob(\"*.png\"))\n",
    "random.shuffle(imgs)\n",
    "sel = imgs[:min(len(imgs), SAMPLES_PER_SPLIT)]\n",
    "\n",
    "for img_path in tqdm(sel):\n",
    "    lbl_path = NEW_LABELS_DIR / f\"{img_path.stem}.txt\"\n",
    "    out_path = PREVIEW_DIR / f\"new_{img_path.name}\"\n",
    "    draw_yolo_polygons(img_path, lbl_path, out_path)\n",
    "\n",
    "print(f\"Showing {len(sel)} samples from NEW auto-labeled images (not existing fixed_val)\")\n",
    "print(\"Previews written to\")\n",
    "PREVIEW_DIR.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "589d4757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in fixed_val: 47\n",
      "Previews in PREVIEW_DIR: 13\n",
      "Images to delete from fixed_val (not in previews): 34\n",
      "\n",
      "Images that will be REMOVED from fixed_val:\n",
      "  - 042b9e09b3832319fe998ffb4bf44edd\n",
      "  - 088610ac49bfde8470097a40c8b749d7\n",
      "  - 0ac39c0cadb518e8bcc8de34579b625f\n",
      "  - 0af6fd9d3636fd6403c7ada6c8a10530\n",
      "  - 0d4db7c113776bc0a401d833d556df84\n",
      "  - 1104093f8577602bb0425f1ccd118de9\n",
      "  - 11cb69ea752cefa3a8cad413598028de\n",
      "  - 19d18a004fb8ffcae5740d3bc9f87d78\n",
      "  - 1ff6f7af4e054a1c879c6485194e44cb\n",
      "  - 205637f0b04837de28f8d5c031b263bc\n",
      "  - 256c86658031f676fe03b3516f9a899b\n",
      "  - 268049ede7cfd5c42204b885785fcfc1\n",
      "  - 29b6473d55641a2d6a06276b9357090f\n",
      "  - 2b9a10a9f16323fd28c304e1b18f4787\n",
      "  - 366acb21b00b40588372736b95776fac\n",
      "  - 6ea339039c57d22328a8a9097181b4cb\n",
      "  - 7dbbf64f4372e8af631d5b3261e5d6aa\n",
      "  - 9666760cde1bedabf437f3dbfc95f891\n",
      "  - 9d5cda5391d6ae193428fbb451d0c905\n",
      "  - 9ecb763ade7cb05b25ab6f784d29744f\n",
      "  - a0efc5e34c785282ee484a5e64e1c8ea\n",
      "  - a56abe595542342e6049fb8dc0fccf8c\n",
      "  - a6b631525ff8dc9bc26bb53e97481606\n",
      "  - b2dcc2d8cc39ca13b5cf2e24bf036d62\n",
      "  - b5a9eceece731289df933a2d89cd24db\n",
      "  - d634b2ebe37b5735c16949926ae2d7bb\n",
      "  - d8ce4c69557862b45c0f7c18d0d3a412\n",
      "  - daa535a4bc8e19b7dd0f0bdf7d891459\n",
      "  - e1117a3b7a26ccff17879b5789f02d0b\n",
      "  - e912cfb70231fd6c25c18171bdee8674\n",
      "  - eb36d794d60789ff4af3a2b30beb228e\n",
      "  - f6448893a6bb9e4fa65a51298149599d\n",
      "  - f6a796ac0c1825320b64a4d3ece90068\n",
      "  - fc28e08f6ae00529bd6e6f3092bc589b\n",
      "\n",
      "→ To DELETE these rejected images, set CLEAN_UP = True and rerun this cell\n"
     ]
    }
   ],
   "source": [
    "# Clean up rejected previews\n",
    "# Scan PREVIEW_DIR to find which images you manually deleted\n",
    "# Then remove the corresponding images/labels from fixed_val\n",
    "\n",
    "# Get all previews currently in PREVIEW_DIR\n",
    "PREVIEW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "existing_previews = {p.stem.replace(\"new_\", \"\") for p in PREVIEW_DIR.glob(\"*\")}\n",
    "\n",
    "# Get all images in fixed_val\n",
    "fixed_val_images = set(p.stem for p in (PROJECT_DIR / \"images\").glob(\"*.jpg\"))\n",
    "fixed_val_images.update(p.stem for p in (PROJECT_DIR / \"images\").glob(\"*.png\"))\n",
    "\n",
    "# Find images that were added but are NOT in previews anymore (= manually deleted by user)\n",
    "deleted_by_user = fixed_val_images - existing_previews\n",
    "\n",
    "print(f\"Images in fixed_val: {len(fixed_val_images)}\")\n",
    "print(f\"Previews in PREVIEW_DIR: {len(existing_previews)}\")\n",
    "print(f\"Images to delete from fixed_val (not in previews): {len(deleted_by_user)}\")\n",
    "\n",
    "if deleted_by_user:\n",
    "    print(\"\\nImages that will be REMOVED from fixed_val:\")\n",
    "    for img_stem in sorted(deleted_by_user):\n",
    "        print(f\"  - {img_stem}\")\n",
    "    \n",
    "    # Flag to control cleanup\n",
    "    CLEAN_UP = False  # Set to True to actually delete\n",
    "    \n",
    "    if CLEAN_UP:\n",
    "        cleaned = 0\n",
    "        for img_stem in deleted_by_user:\n",
    "            # Find the actual image file (could be .jpg ou .png)\n",
    "            img_file = None\n",
    "            for ext in ['.jpg', '.jpeg', '.png']:\n",
    "                candidate = PROJECT_DIR / \"images\" / f\"{img_stem}{ext}\"\n",
    "                if candidate.exists():\n",
    "                    img_file = candidate\n",
    "                    break\n",
    "            \n",
    "            if img_file:\n",
    "                img_file.unlink()\n",
    "                cleaned += 1\n",
    "            \n",
    "            # Remove corresponding label\n",
    "            lbl_file = PROJECT_DIR / \"labels\" / f\"{img_stem}.txt\"\n",
    "            if lbl_file.exists():\n",
    "                lbl_file.unlink()\n",
    "        \n",
    "        print(f\"\\n✓ Cleaned up {cleaned} rejected images and their labels from fixed_val\")\n",
    "    else:\n",
    "        print(\"\\n→ To DELETE these rejected images, set CLEAN_UP = True and rerun this cell\")\n",
    "else:\n",
    "    print(\"✓ All previewed images are still in PREVIEW_DIR (no cleanup needed)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
