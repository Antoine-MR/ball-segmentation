{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61912fa9",
   "metadata": {},
   "source": [
    "## Step 1: Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f4b50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from ultralytics.models import YOLO\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a02f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DisplayPath\n",
    "Path = DisplayPath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab13785",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "896cd42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset](datasets/ready/full_dataset)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset/train](datasets/ready/full_dataset/train)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset/val](datasets/ready/full_dataset/val)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset/test](datasets/ready/full_dataset/test)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dataset path (created by e2e_data_prep.ipynb)\n",
    "YOLO_DATASET = Path(\"datasets/ready/full_dataset\")\n",
    "RUNS_DIR = Path(\"runs/segment\")\n",
    "\n",
    "# Verify dataset exists\n",
    "if not YOLO_DATASET.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found at {YOLO_DATASET}. Run e2e_data_prep.ipynb first!\")\n",
    "\n",
    "print(\"Dataset:\")\n",
    "YOLO_DATASET.display()\n",
    "print(\"  Train:\")\n",
    "(YOLO_DATASET / 'train').display()\n",
    "print(\"  Val:\")\n",
    "(YOLO_DATASET / 'val').display()\n",
    "print(\"  Test:\")\n",
    "(YOLO_DATASET / 'test').display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9818581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "GPU: NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "CUDA: 12.8\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 640\n",
    "model_type = \"yolo11n-seg.pt\"\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49612aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUG_CONFIG = {\n",
    "    'hsv_h': 0.015,  # Hue augmentation\n",
    "    'hsv_s': 0.7,    # Saturation\n",
    "    'hsv_v': 0.4,    # Value\n",
    "    'degrees': 10.0,  # Rotation\n",
    "    'translate': 0.1, # Translation\n",
    "    'scale': 0.5,     # Scaling\n",
    "    'shear': 0.0,     # Shearing\n",
    "    'perspective': 0.0, # Perspective\n",
    "    'flipud': 0.0,    # Vertical flip\n",
    "    'fliplr': 0.5,    # Horizontal flip\n",
    "    'mosaic': 1.0,    # Mosaic augmentation\n",
    "    'mixup': 0.0,     # Mixup augmentation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b37a05",
   "metadata": {},
   "source": [
    "## Step 3: Verify Dataset Structure\n",
    "\n",
    "Dataset is already prepared by e2e_data_prep.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b684ea2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET VERIFICATION\n",
      "============================================================\n",
      "TRAIN:  998 images,  998 labels\n",
      "VAL  :   47 images,   47 labels\n",
      "TEST :  209 images,  209 labels\n",
      "TOTAL: 1254 images, 1254 labels\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Verify dataset structure\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET VERIFICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "stats = {}\n",
    "\n",
    "for split in splits:\n",
    "    img_dir = YOLO_DATASET / split / \"images\"\n",
    "    lbl_dir = YOLO_DATASET / split / \"labels\"\n",
    "    \n",
    "    if img_dir.exists() and lbl_dir.exists():\n",
    "        num_images = len(list(img_dir.glob(\"*\")))\n",
    "        num_labels = len(list(lbl_dir.glob(\"*.txt\")))\n",
    "        stats[split] = {'images': num_images, 'labels': num_labels}\n",
    "        print(f\"{split.upper():5s}: {num_images:4d} images, {num_labels:4d} labels\")\n",
    "    else:\n",
    "        stats[split] = {'images': 0, 'labels': 0}\n",
    "        print(f\"{split.upper():5s}: Missing!\")\n",
    "\n",
    "total_images = sum(s['images'] for s in stats.values())\n",
    "total_labels = sum(s['labels'] for s in stats.values())\n",
    "\n",
    "print(f\"{'TOTAL':5s}: {total_images:4d} images, {total_labels:4d} labels\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if total_images == 0:\n",
    "    raise RuntimeError(\"No dataset found! Run e2e_data_prep.ipynb to create the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b201a0",
   "metadata": {},
   "source": [
    "## Step 4: Create YOLO Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a95ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Configuration saved: datasets/ready/full_dataset/data.yaml\n",
      "Dataset structure:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset](datasets/ready/full_dataset)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset/train](datasets/ready/full_dataset/train)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset/val](datasets/ready/full_dataset/val)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Test:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[datasets/ready/full_dataset/test](datasets/ready/full_dataset/test)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = {\n",
    "    'red ball': 0,\n",
    "    'human': 1,\n",
    "    'trashcan': 2\n",
    "}\n",
    "\n",
    "config = {\n",
    "    'path': str(YOLO_DATASET.absolute()),\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'nc': len(classes),\n",
    "    'names': list(classes.keys())\n",
    "}\n",
    "\n",
    "config_path = YOLO_DATASET / 'data.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"‚úì Configuration saved: {config_path}\")\n",
    "print(\"Dataset structure:\")\n",
    "YOLO_DATASET.display()\n",
    "print(\"  Train:\")\n",
    "(YOLO_DATASET / 'train').display()\n",
    "print(\"  Val:\")\n",
    "(YOLO_DATASET / 'val').display()\n",
    "print(\"  Test:\")\n",
    "(YOLO_DATASET / 'test').display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef74bc8",
   "metadata": {},
   "source": [
    "## Step 5: Train Model\n",
    "\n",
    "Train YOLOv11 with:\n",
    "- Data augmentation on train set\n",
    "- Checkpoints saved for best model\n",
    "- Validation after each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725e52a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained model\n",
    "model = YOLO(model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44d36c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'ball_person_trashcan_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c800894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.246 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.235 üöÄ Python-3.12.10 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=datasets/ready/full_dataset/data.yaml, degrees=10.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=500, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22], half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=ball_person_trashcan_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/segment, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/tonino/projects/ball segmentation/runs/segment/ball_person_trashcan_model, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    684025  ultralytics.nn.modules.head.Segment          [3, 32, 64, [64, 128, 256]]   \n",
      "YOLO11n-seg summary: 203 layers, 2,843,193 parameters, 2,843,177 gradients, 9.7 GFLOPs\n",
      "\n",
      "Transferred 510/561 items from pretrained weights\n",
      "Freezing layer 'model.0.conv.weight'\n",
      "Freezing layer 'model.0.bn.weight'\n",
      "Freezing layer 'model.0.bn.bias'\n",
      "Freezing layer 'model.1.conv.weight'\n",
      "Freezing layer 'model.1.bn.weight'\n",
      "Freezing layer 'model.1.bn.bias'\n",
      "Freezing layer 'model.2.cv1.conv.weight'\n",
      "Freezing layer 'model.2.cv1.bn.weight'\n",
      "Freezing layer 'model.2.cv1.bn.bias'\n",
      "Freezing layer 'model.2.cv2.conv.weight'\n",
      "Freezing layer 'model.2.cv2.bn.weight'\n",
      "Freezing layer 'model.2.cv2.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.2.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.2.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.3.conv.weight'\n",
      "Freezing layer 'model.3.bn.weight'\n",
      "Freezing layer 'model.3.bn.bias'\n",
      "Freezing layer 'model.4.cv1.conv.weight'\n",
      "Freezing layer 'model.4.cv1.bn.weight'\n",
      "Freezing layer 'model.4.cv1.bn.bias'\n",
      "Freezing layer 'model.4.cv2.conv.weight'\n",
      "Freezing layer 'model.4.cv2.bn.weight'\n",
      "Freezing layer 'model.4.cv2.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.4.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.4.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.5.conv.weight'\n",
      "Freezing layer 'model.5.bn.weight'\n",
      "Freezing layer 'model.5.bn.bias'\n",
      "Freezing layer 'model.6.cv1.conv.weight'\n",
      "Freezing layer 'model.6.cv1.bn.weight'\n",
      "Freezing layer 'model.6.cv1.bn.bias'\n",
      "Freezing layer 'model.6.cv2.conv.weight'\n",
      "Freezing layer 'model.6.cv2.bn.weight'\n",
      "Freezing layer 'model.6.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.6.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.6.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.7.conv.weight'\n",
      "Freezing layer 'model.7.bn.weight'\n",
      "Freezing layer 'model.7.bn.bias'\n",
      "Freezing layer 'model.8.cv1.conv.weight'\n",
      "Freezing layer 'model.8.cv1.bn.weight'\n",
      "Freezing layer 'model.8.cv1.bn.bias'\n",
      "Freezing layer 'model.8.cv2.conv.weight'\n",
      "Freezing layer 'model.8.cv2.bn.weight'\n",
      "Freezing layer 'model.8.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.8.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.8.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.9.cv1.conv.weight'\n",
      "Freezing layer 'model.9.cv1.bn.weight'\n",
      "Freezing layer 'model.9.cv1.bn.bias'\n",
      "Freezing layer 'model.9.cv2.conv.weight'\n",
      "Freezing layer 'model.9.cv2.bn.weight'\n",
      "Freezing layer 'model.9.cv2.bn.bias'\n",
      "Freezing layer 'model.10.cv1.conv.weight'\n",
      "Freezing layer 'model.10.cv1.bn.weight'\n",
      "Freezing layer 'model.10.cv1.bn.bias'\n",
      "Freezing layer 'model.10.cv2.conv.weight'\n",
      "Freezing layer 'model.10.cv2.bn.weight'\n",
      "Freezing layer 'model.10.cv2.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.qkv.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.proj.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.proj.bn.bias'\n",
      "Freezing layer 'model.10.m.0.attn.pe.conv.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.weight'\n",
      "Freezing layer 'model.10.m.0.attn.pe.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.0.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.0.bn.bias'\n",
      "Freezing layer 'model.10.m.0.ffn.1.conv.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.weight'\n",
      "Freezing layer 'model.10.m.0.ffn.1.bn.bias'\n",
      "Freezing layer 'model.13.cv1.conv.weight'\n",
      "Freezing layer 'model.13.cv1.bn.weight'\n",
      "Freezing layer 'model.13.cv1.bn.bias'\n",
      "Freezing layer 'model.13.cv2.conv.weight'\n",
      "Freezing layer 'model.13.cv2.bn.weight'\n",
      "Freezing layer 'model.13.cv2.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.13.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.13.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.16.cv1.conv.weight'\n",
      "Freezing layer 'model.16.cv1.bn.weight'\n",
      "Freezing layer 'model.16.cv1.bn.bias'\n",
      "Freezing layer 'model.16.cv2.conv.weight'\n",
      "Freezing layer 'model.16.cv2.bn.weight'\n",
      "Freezing layer 'model.16.cv2.bn.bias'\n",
      "Freezing layer 'model.16.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.16.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.16.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.16.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.16.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.16.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.17.conv.weight'\n",
      "Freezing layer 'model.17.bn.weight'\n",
      "Freezing layer 'model.17.bn.bias'\n",
      "Freezing layer 'model.19.cv1.conv.weight'\n",
      "Freezing layer 'model.19.cv1.bn.weight'\n",
      "Freezing layer 'model.19.cv1.bn.bias'\n",
      "Freezing layer 'model.19.cv2.conv.weight'\n",
      "Freezing layer 'model.19.cv2.bn.weight'\n",
      "Freezing layer 'model.19.cv2.bn.bias'\n",
      "Freezing layer 'model.19.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.19.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.19.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.19.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.19.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.19.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.20.conv.weight'\n",
      "Freezing layer 'model.20.bn.weight'\n",
      "Freezing layer 'model.20.bn.bias'\n",
      "Freezing layer 'model.22.cv1.conv.weight'\n",
      "Freezing layer 'model.22.cv1.bn.weight'\n",
      "Freezing layer 'model.22.cv1.bn.bias'\n",
      "Freezing layer 'model.22.cv2.conv.weight'\n",
      "Freezing layer 'model.22.cv2.bn.weight'\n",
      "Freezing layer 'model.22.cv2.bn.bias'\n",
      "Freezing layer 'model.22.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.22.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.22.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.22.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.22.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.22.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.22.m.0.cv3.conv.weight'\n",
      "Freezing layer 'model.22.m.0.cv3.bn.weight'\n",
      "Freezing layer 'model.22.m.0.cv3.bn.bias'\n",
      "Freezing layer 'model.22.m.0.m.0.cv1.conv.weight'\n",
      "Freezing layer 'model.22.m.0.m.0.cv1.bn.weight'\n",
      "Freezing layer 'model.22.m.0.m.0.cv1.bn.bias'\n",
      "Freezing layer 'model.22.m.0.m.0.cv2.conv.weight'\n",
      "Freezing layer 'model.22.m.0.m.0.cv2.bn.weight'\n",
      "Freezing layer 'model.22.m.0.m.0.cv2.bn.bias'\n",
      "Freezing layer 'model.22.m.0.m.1.cv1.conv.weight'\n",
      "Freezing layer 'model.22.m.0.m.1.cv1.bn.weight'\n",
      "Freezing layer 'model.22.m.0.m.1.cv1.bn.bias'\n",
      "Freezing layer 'model.22.m.0.m.1.cv2.conv.weight'\n",
      "Freezing layer 'model.22.m.0.m.1.cv2.bn.weight'\n",
      "Freezing layer 'model.22.m.0.m.1.cv2.bn.bias'\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 124.8¬±133.2 MB/s, size: 77.7 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/labels.cache... 997 images, 3 backgrounds, 1 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 998/998 1.1Mit/s 0.0s0s\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/0db65afcb80a13863a3a8dfc24e7d73a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/1731534619a61f5dc5f63c0414915afb.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/1c04a053b46c5e78a4a93e76cc80d233.jpg: 5 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/1e82f7995240b5e6e1fc33e649219375.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/20b90386dd79ffcfbd94b9868ac62cc5.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/2db66d2c671556fda7813b34ef672ee3.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/31aab9bb7708794e4777bf399873f529.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/432990e6d8d154c8c60fb4e0570b452a.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/491e62d4bb9e70806db0a13b6abe99ed.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/571d71a897f478abf9fbd6a4bb667ded.jpg: ignoring corrupt image/label: image size (9, 16) <10 pixels\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/5e584bc79700ada6170545cdd5f0628c.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/77449fbf91a6c8f66fc6d24a6d55cb91.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/7bc696523e818d843abe7c38ff7d9588.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/7d08dd1bd72cb79b59b73d90d1487a71.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/7ee3ed09be312fac168b140fdca3bc75.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/8386b8b7f9b1b19d822eebcb7431edef.jpg: 2 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/87fbc3315fe5abc3142de03b5bb96af0.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/8a0dab3a8810f7aac82708d97d17dcea.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/8b8e121636bf2158a7052e0a297e36a1.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/b89006dfbf0861ad3cf9f5161bb1b16f.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/dfe44d08ed9d881f01ed3d9acd374772.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/e74a8de4f129a1d33c6dc3320d04d8d6.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0m/home/tonino/projects/ball segmentation/datasets/ready/full_dataset/train/images/eac3d40199892716e311067c141ec999.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 488.0¬±58.8 MB/s, size: 2921.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/labels.cache... 47 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 47/47 52.0Kit/s 0.0s\n",
      "Plotting labels to /home/tonino/projects/ball segmentation/runs/segment/ball_person_trashcan_model/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 90 weight(decay=0.0), 101 weight(decay=0.0005), 100 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/ball_person_trashcan_model\u001b[0m\n",
      "Starting training for 500 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/500      1.82G     0.8786      2.674      2.241      1.165         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 2.1s/it 2:090.8ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 7.6s/it 15.2s25.9s\n",
      "                   all         47         81     0.0033      0.618      0.277      0.257     0.0021      0.382      0.111     0.0512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/500         2G      0.895      2.528      1.496      1.182         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 2.2it/s 28.4s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s1.9s\n",
      "                   all         47         81      0.416      0.473      0.447      0.405      0.416      0.473      0.445       0.22\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/500         2G     0.9006      2.542      1.415      1.175         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.2it/s 15.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s1.4s\n",
      "                   all         47         81      0.535       0.49      0.492      0.441      0.535       0.49      0.486      0.363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/500      2.01G     0.8942       2.49      1.327      1.178         21        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.3it/s 0.9s1.9s\n",
      "                   all         47         81      0.474      0.483      0.482      0.437      0.474      0.483      0.477      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/500      2.02G     0.8876      2.408      1.266      1.155         75        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.9it/s 13.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.2it/s 0.6s1.4s\n",
      "                   all         47         81      0.443        0.5      0.492       0.45      0.443        0.5      0.491      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/500      2.02G     0.8934       2.49      1.277      1.167         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s1.6s\n",
      "                   all         47         81      0.437      0.471      0.478       0.42      0.437      0.471      0.476      0.345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/500      2.03G     0.8789      2.432      1.226      1.169         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.9it/s 12.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.9it/s 0.7s1.6s\n",
      "                   all         47         81      0.536      0.412      0.466      0.435      0.536      0.412      0.465      0.381\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/500      2.03G     0.8563       2.38      1.239      1.151         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s1.3s\n",
      "                   all         47         81      0.436        0.5      0.488      0.452      0.436        0.5      0.486      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/500      2.03G     0.8565      2.377      1.236      1.148         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.4it/s 0.6s1.2s\n",
      "                   all         47         81      0.421      0.451      0.479      0.444      0.421      0.451      0.477      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/500      2.03G     0.8328       2.36      1.195      1.141         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.5it/s 13.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s1.4s\n",
      "                   all         47         81      0.579      0.418      0.494      0.456      0.579      0.418      0.491      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/500      2.03G     0.8753      2.415      1.196      1.165         47        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.5it/s 14.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s1.6s\n",
      "                   all         47         81      0.495       0.48      0.516      0.472      0.495       0.48      0.512      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/500      2.03G     0.8584      2.392       1.18      1.153         41        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.7it/s 13.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s1.6s\n",
      "                   all         47         81      0.542      0.461      0.523       0.48      0.542      0.461      0.521       0.42\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/500      2.03G     0.8397      2.425      1.155      1.138         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.7it/s 13.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.1it/s 0.6s1.3s\n",
      "                   all         47         81      0.555      0.422      0.483      0.447      0.555      0.422      0.483      0.401\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/500      2.03G     0.8225      2.299      1.128      1.123         52        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.9it/s 13.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.9it/s 0.7s1.4s\n",
      "                   all         47         81      0.482      0.431      0.472      0.441      0.482      0.431      0.471      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/500      2.03G     0.8028      2.249      1.103      1.103         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.5it/s 14.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s1.4s\n",
      "                   all         47         81      0.585      0.392      0.469      0.435      0.585      0.392      0.466      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/500      2.03G     0.8392      2.327      1.135      1.138         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.4it/s 14.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s1.7s\n",
      "                   all         47         81      0.551      0.435      0.508      0.466      0.551      0.435      0.508      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/500      2.03G     0.8177      2.321      1.108      1.132         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.7it/s 13.4s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.4it/s 1.5s1.3s\n",
      "                   all         47         81      0.535      0.453       0.53      0.483      0.535      0.453      0.525      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/500      2.03G     0.8296      2.307        1.1      1.126         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.8it/s 13.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.3it/s 0.6s1.2s\n",
      "                   all         47         81      0.498       0.48      0.514       0.47      0.498       0.48      0.513      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/500      2.03G     0.8206      2.268      1.098      1.131         28        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 5.0it/s 12.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.3it/s 0.6s1.3s\n",
      "                   all         47         81       0.52      0.441      0.509       0.47       0.52      0.441      0.505      0.411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/500      2.03G     0.8251      2.277      1.109      1.124         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.3it/s 14.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s1.4s\n",
      "                   all         47         81      0.552       0.46      0.521      0.482      0.552       0.46      0.519      0.425\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/500      2.03G     0.8228       2.28      1.096      1.124         37        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.5it/s 13.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.4it/s 0.8s1.6s\n",
      "                   all         47         81       0.62      0.391      0.456      0.422       0.62      0.391      0.455      0.377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/500      2.03G     0.8218      2.306      1.097      1.131         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.7s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s1.4s\n",
      "                   all         47         81      0.581      0.437      0.487      0.443      0.581      0.437      0.487      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/500      2.03G     0.8295      2.228      1.062      1.113         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.9it/s 12.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.3it/s 0.6s1.3s\n",
      "                   all         47         81      0.491      0.451      0.512      0.466      0.491      0.451       0.51      0.408\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/500      2.03G     0.8262      2.302      1.078      1.131         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.0it/s 0.7s1.4s\n",
      "                   all         47         81      0.583      0.398      0.494      0.461      0.583      0.398      0.493       0.41\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/500      2.03G     0.8031      2.277      1.068      1.118         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 5.2it/s 12.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s1.5s\n",
      "                   all         47         81      0.511      0.451      0.505      0.474      0.511      0.451      0.503      0.416\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/500      2.03G     0.8297      2.358      1.081      1.129         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 5.1it/s 12.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.4it/s 0.6s1.2s\n",
      "                   all         47         81      0.618      0.426       0.51       0.47      0.618      0.426      0.509      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/500      2.03G      0.799      2.288      1.069      1.122         49        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.8it/s 13.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.4it/s 0.6s1.2s\n",
      "                   all         47         81      0.586      0.417      0.497      0.452      0.586      0.417      0.497      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/500      2.03G      0.785      2.171      1.064      1.111         68        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.8it/s 13.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s1.4s\n",
      "                   all         47         81      0.573      0.461      0.521      0.484      0.573      0.461      0.521      0.428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/500      2.03G     0.8182      2.235      1.062      1.114         52        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.5it/s 14.1s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.4it/s 0.6s1.2s\n",
      "                   all         47         81      0.606      0.402      0.485      0.449      0.606      0.402      0.485      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/500      2.03G     0.7946      2.217      1.056      1.118         48        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 5.2it/s 12.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.9it/s 0.7s1.5s\n",
      "                   all         47         81      0.556      0.461      0.493      0.443      0.556      0.461      0.492      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/500      2.03G     0.8038      2.214      1.061       1.12         24        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.7it/s 13.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.4it/s 0.6s1.2s\n",
      "                   all         47         81      0.509      0.441      0.481      0.442      0.509      0.441      0.481      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/500      2.03G     0.8266      2.361      1.084      1.146         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 5.2it/s 12.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.3it/s 0.6s1.2s\n",
      "                   all         47         81      0.568      0.436      0.514      0.473      0.568      0.436      0.514      0.421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/500      2.03G     0.7809      2.215      1.043      1.101         54        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.8it/s 13.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.2it/s 0.6s1.3s\n",
      "                   all         47         81      0.588      0.413      0.494      0.452      0.588      0.413      0.494      0.406\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/500      2.03G     0.7993      2.197      1.044       1.11         58        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.7it/s 13.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s1.4s\n",
      "                   all         47         81      0.474       0.48      0.505      0.463      0.474       0.48      0.504      0.414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/500      2.03G     0.7989      2.228      1.038      1.125         31        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 5.1it/s 12.3s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.2it/s 0.6s1.2s\n",
      "                   all         47         81      0.488      0.431      0.457      0.425      0.488      0.431      0.457      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/500      2.03G     0.7925       2.23      1.012      1.093         17        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.8it/s 13.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.3it/s 0.6s1.3s\n",
      "                   all         47         81      0.442      0.451      0.459       0.43      0.442      0.451      0.454      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/500      2.03G     0.7883      2.245      1.045      1.116         33        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 5.1it/s 12.3s0.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.1it/s 0.6s1.4s\n",
      "                   all         47         81      0.605      0.394      0.498      0.456      0.605      0.394      0.487      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/500      2.03G     0.7991       2.19      1.025      1.113         34        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.4it/s 14.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.5it/s 0.8s1.9s\n",
      "                   all         47         81       0.55       0.45      0.497      0.463       0.55       0.45       0.49      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/500      2.03G     0.8117      2.254      1.054      1.118         27        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.9it/s 13.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.2it/s 0.6s1.2s\n",
      "                   all         47         81      0.514      0.441      0.479      0.442      0.514      0.441      0.478      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/500      2.03G     0.7815      2.206      1.033      1.104         30        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.6s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s1.7s\n",
      "                   all         47         81      0.498       0.45      0.501      0.462      0.498       0.45        0.5      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/500      2.03G     0.7968      2.235      1.009      1.107         35        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.4it/s 14.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.6it/s 0.8s1.7s\n",
      "                   all         47         81      0.549      0.442      0.499       0.47      0.549      0.442      0.499      0.415\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/500      2.03G     0.7918      2.212      1.023      1.103         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.5it/s 14.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.7it/s 0.7s1.5s\n",
      "                   all         47         81      0.582      0.399      0.471      0.441      0.582      0.399      0.471      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/500      2.03G     0.8047      2.204      1.017      1.117         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.7it/s 13.5s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.5it/s 0.6s1.2s\n",
      "                   all         47         81      0.505      0.475      0.509       0.47      0.505      0.475      0.509      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/500      2.03G     0.8196      2.255      1.045      1.124         45        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.9it/s 12.9s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.9it/s 0.7s1.3s\n",
      "                   all         47         81        0.5      0.471      0.494      0.468        0.5      0.471      0.494      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/500      2.03G     0.8288      2.275      1.024      1.127         29        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.6it/s 13.8s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.5it/s 0.6s1.2s\n",
      "                   all         47         81       0.63      0.395      0.496      0.459       0.63      0.395      0.496      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/500      2.03G     0.7881      2.154      1.007      1.099         77        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.8it/s 13.0s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 3.3it/s 0.6s1.3s\n",
      "                   all         47         81      0.629        0.4      0.496      0.461      0.629        0.4      0.496      0.413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/500      2.03G      0.797      2.175      1.005      1.115         53        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.8it/s 13.1s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.8it/s 0.7s1.5s\n",
      "                   all         47         81      0.609      0.441      0.506      0.473      0.609      0.441      0.505      0.417\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/500      2.03G     0.7856      2.146      1.013      1.103         55        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 63/63 4.7it/s 13.4s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 2.9it/s 0.7s1.5s\n",
      "                   all         47         81      0.501      0.446      0.476      0.449      0.501      0.446      0.476      0.385\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 20 epochs. Best results observed at epoch 28, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=20) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "48 epochs completed in 0.234 hours.\n",
      "Optimizer stripped from /home/tonino/projects/ball segmentation/runs/segment/ball_person_trashcan_model/weights/last.pt, 6.0MB\n",
      "Optimizer stripped from /home/tonino/projects/ball segmentation/runs/segment/ball_person_trashcan_model/weights/best.pt, 6.0MB\n",
      "\n",
      "Validating /home/tonino/projects/ball segmentation/runs/segment/ball_person_trashcan_model/weights/best.pt...\n",
      "Ultralytics 8.3.235 üöÄ Python-3.12.10 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192MiB)\n",
      "YOLO11n-seg summary (fused): 113 layers, 2,835,153 parameters, 0 gradients, 9.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2/2 1.6it/s 1.3s2.8s\n",
      "                   all         47         81      0.573      0.461      0.521      0.484      0.573      0.461      0.521      0.427\n",
      "              red ball         34         34       0.99      0.382      0.594      0.519       0.99      0.382      0.594      0.483\n",
      "                 human         34         34       0.73          1      0.971      0.933       0.73          1      0.971      0.798\n",
      "              trashcan         13         13          0          0          0          0          0          0          0          0\n",
      "Speed: 0.5ms preprocess, 6.4ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/ball_person_trashcan_model\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "head_idx = next((i for i, m in enumerate(model.model.model) if 'Detect' in m.__class__.__name__ or 'Segment' in m.__class__.__name__), len(model.model.model) - 1)\n",
    "results = model.train(\n",
    "    data=str(config_path),\n",
    "    epochs=500,\n",
    "    freeze=list(range(head_idx)),\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    project=str(RUNS_DIR),\n",
    "    name=project_name,\n",
    "    exist_ok=True,\n",
    "    \n",
    "    # Checkpointing\n",
    "    save=True,\n",
    "    save_period=1,  # Save every epoch\n",
    "    \n",
    "    # Validation\n",
    "    val=True,\n",
    "    \n",
    "    # Data augmentation (only applied to train)\n",
    "    **AUG_CONFIG,\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer='Adam',\n",
    "    lr0=0.001,\n",
    "    lrf=0.01,\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    \n",
    "    # Loss weights\n",
    "    box=7.5,\n",
    "    cls=0.5,\n",
    "    dfl=1.5,\n",
    "    \n",
    "    # Other\n",
    "    patience=20,  # Early stopping\n",
    "    workers=8,\n",
    "\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d5939d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "[runs/segment/ball_person_trashcan_model/weights/best.pt](runs/segment/ball_person_trashcan_model/weights/best.pt)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model = Path('./runs/segment/ball_person_trashcan_model/weights/best.pt')\n",
    "best_model.display()\n",
    "model = YOLO(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfbe082",
   "metadata": {},
   "source": [
    "## Step 6: Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83cf529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.235 üöÄ Python-3.12.10 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3080 Laptop GPU, 8192MiB)\n",
      "YOLO11n-seg summary (fused): 113 layers, 2,835,153 parameters, 0 gradients, 9.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 1156.9¬±392.0 MB/s, size: 2696.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/labels.cache... 47 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 47/47 35.8Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 3/3 6.2s/it 18.6s5.0s4\n",
      "                   all         47         81      0.573      0.461      0.522      0.486      0.573      0.461      0.522      0.425\n",
      "              red ball         34         34      0.987      0.382      0.594      0.526      0.987      0.382      0.594      0.478\n",
      "                 human         34         34      0.731          1      0.971      0.933      0.731          1      0.971      0.798\n",
      "              trashcan         13         13          0          0          0          0          0          0          0          0\n",
      "Speed: 9.3ms preprocess, 30.3ms inference, 0.0ms loss, 17.3ms postprocess per image\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/val15\u001b[0m\n",
      "\n",
      "============================================================\n",
      "VALIDATION METRICS\n",
      "============================================================\n",
      "Box mAP50: 0.5216\n",
      "Box mAP50-95: 0.4862\n",
      "Mask mAP50: 0.5216\n",
      "Mask mAP50-95: 0.4251\n"
     ]
    }
   ],
   "source": [
    "# Validation metrics\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"VALIDATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Box mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"Box mAP50-95: {metrics.box.map:.4f}\")\n",
    "print(f\"Mask mAP50: {metrics.seg.map50:.4f}\")\n",
    "print(f\"Mask mAP50-95: {metrics.seg.map:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c072d1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[runs/segment/ball_person_trashcan_model/weights/best.pt](runs/segment/ball_person_trashcan_model/weights/best.pt)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Last model: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[runs/segment/ball_person_trashcan_model/weights/last.pt](runs/segment/ball_person_trashcan_model/weights/last.pt)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Results: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[runs/segment/ball_person_trashcan_model](runs/segment/ball_person_trashcan_model)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Find best checkpoint\n",
    "model_dir = RUNS_DIR / project_name\n",
    "best_model = model_dir / 'weights' / 'best.pt'\n",
    "last_model = model_dir / 'weights' / 'last.pt'\n",
    "\n",
    "print(f\"Best model: \")\n",
    "best_model.display()\n",
    "print(f\"   Last model: \")\n",
    "last_model.display()\n",
    "print(f\"   Results: \")\n",
    "model_dir.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fec1d1",
   "metadata": {},
   "source": [
    "## Step 7: Test on Sample Images (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a42f9f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 47 sample images...\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/366acb21b00b40588372736b95776fac.jpg: 640x480 1 red ball, 1 human, 70.3ms\n",
      "Speed: 3.3ms preprocess, 70.3ms inference, 7.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 366acb21b00b40588372736b95776fac.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/0d4db7c113776bc0a401d833d556df84.jpg: 640x480 1 red ball, 1 human, 12.8ms\n",
      "Speed: 2.3ms preprocess, 12.8ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 0d4db7c113776bc0a401d833d556df84.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/a6b631525ff8dc9bc26bb53e97481606.jpg: 640x480 1 human, 27.9ms\n",
      "Speed: 2.1ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì a6b631525ff8dc9bc26bb53e97481606.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/6ea339039c57d22328a8a9097181b4cb.jpg: 640x480 1 human, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 6ea339039c57d22328a8a9097181b4cb.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/fc28e08f6ae00529bd6e6f3092bc589b.jpg: 640x480 1 human, 14.4ms\n",
      "Speed: 2.2ms preprocess, 14.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì fc28e08f6ae00529bd6e6f3092bc589b.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/256c86658031f676fe03b3516f9a899b.jpg: 640x480 1 human, 15.2ms\n",
      "Speed: 2.3ms preprocess, 15.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 256c86658031f676fe03b3516f9a899b.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/de96513c1cdccc864e7b7e809162d06c.jpg: 640x480 (no detections), 13.9ms\n",
      "Speed: 2.0ms preprocess, 13.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì de96513c1cdccc864e7b7e809162d06c.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/b6fe1fc46e4ad868193c424070da1e34.jpg: 640x480 1 human, 13.7ms\n",
      "Speed: 2.4ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì b6fe1fc46e4ad868193c424070da1e34.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/088610ac49bfde8470097a40c8b749d7.jpg: 640x480 1 human, 13.0ms\n",
      "Speed: 2.3ms preprocess, 13.0ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 088610ac49bfde8470097a40c8b749d7.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/0ac39c0cadb518e8bcc8de34579b625f.jpg: 640x480 1 human, 33.5ms\n",
      "Speed: 2.7ms preprocess, 33.5ms inference, 6.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 0ac39c0cadb518e8bcc8de34579b625f.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/042b9e09b3832319fe998ffb4bf44edd.jpg: 640x480 1 red ball, 3 humans, 12.7ms\n",
      "Speed: 2.1ms preprocess, 12.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 042b9e09b3832319fe998ffb4bf44edd.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/9666760cde1bedabf437f3dbfc95f891.jpg: 640x480 1 human, 13.7ms\n",
      "Speed: 2.3ms preprocess, 13.7ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 9666760cde1bedabf437f3dbfc95f891.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/d8c811abffbf5da563ee451592a24dcd.jpg: 640x480 1 human, 13.9ms\n",
      "Speed: 2.1ms preprocess, 13.9ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì d8c811abffbf5da563ee451592a24dcd.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/a0efc5e34c785282ee484a5e64e1c8ea.jpg: 640x480 2 humans, 13.3ms\n",
      "Speed: 2.2ms preprocess, 13.3ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì a0efc5e34c785282ee484a5e64e1c8ea.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/018c4798e1caea89fb7e38ab66fce0f9.jpg: 640x480 4 humans, 12.3ms\n",
      "Speed: 2.1ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 018c4798e1caea89fb7e38ab66fce0f9.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/daa535a4bc8e19b7dd0f0bdf7d891459.jpg: 640x480 1 red ball, 1 human, 13.2ms\n",
      "Speed: 2.3ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì daa535a4bc8e19b7dd0f0bdf7d891459.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/1ff6f7af4e054a1c879c6485194e44cb.jpg: 640x480 1 red ball, 1 human, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 1ff6f7af4e054a1c879c6485194e44cb.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/1383c4a58a26c7238fbae31ec8e4e660.jpg: 640x480 (no detections), 18.1ms\n",
      "Speed: 2.1ms preprocess, 18.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 1383c4a58a26c7238fbae31ec8e4e660.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/2b9a10a9f16323fd28c304e1b18f4787.jpg: 640x480 1 red ball, 4 humans, 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 2b9a10a9f16323fd28c304e1b18f4787.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/bbabaf39558fe91afb1a7ed8f1693e04.jpg: 640x480 (no detections), 14.4ms\n",
      "Speed: 2.1ms preprocess, 14.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì bbabaf39558fe91afb1a7ed8f1693e04.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/19d18a004fb8ffcae5740d3bc9f87d78.jpg: 640x480 1 human, 13.4ms\n",
      "Speed: 2.3ms preprocess, 13.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 19d18a004fb8ffcae5740d3bc9f87d78.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/9d5cda5391d6ae193428fbb451d0c905.jpg: 640x480 1 human, 13.2ms\n",
      "Speed: 2.2ms preprocess, 13.2ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 9d5cda5391d6ae193428fbb451d0c905.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/f7c36eabf5a95cf548a382f4a6b49050.jpg: 640x480 1 human, 12.9ms\n",
      "Speed: 1.9ms preprocess, 12.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì f7c36eabf5a95cf548a382f4a6b49050.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/b2dcc2d8cc39ca13b5cf2e24bf036d62.jpg: 640x480 1 human, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì b2dcc2d8cc39ca13b5cf2e24bf036d62.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/205637f0b04837de28f8d5c031b263bc.jpg: 640x480 1 red ball, 1 human, 13.7ms\n",
      "Speed: 2.0ms preprocess, 13.7ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 205637f0b04837de28f8d5c031b263bc.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/eb36d794d60789ff4af3a2b30beb228e.jpg: 640x480 1 red ball, 9 humans, 12.6ms\n",
      "Speed: 2.0ms preprocess, 12.6ms inference, 2.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì eb36d794d60789ff4af3a2b30beb228e.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/e912cfb70231fd6c25c18171bdee8674.jpg: 640x480 1 red ball, 4 humans, 23.8ms\n",
      "Speed: 2.1ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì e912cfb70231fd6c25c18171bdee8674.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/268049ede7cfd5c42204b885785fcfc1.jpg: 640x480 1 red ball, 3 humans, 12.3ms\n",
      "Speed: 2.2ms preprocess, 12.3ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 268049ede7cfd5c42204b885785fcfc1.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/cbbcee9485e646dbaf274f323e512852.jpg: 640x480 1 human, 12.8ms\n",
      "Speed: 2.1ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì cbbcee9485e646dbaf274f323e512852.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/a56abe595542342e6049fb8dc0fccf8c.jpg: 640x480 1 red ball, 5 humans, 12.4ms\n",
      "Speed: 2.3ms preprocess, 12.4ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì a56abe595542342e6049fb8dc0fccf8c.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/f6a796ac0c1825320b64a4d3ece90068.jpg: 640x480 1 red ball, 3 humans, 13.5ms\n",
      "Speed: 2.2ms preprocess, 13.5ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì f6a796ac0c1825320b64a4d3ece90068.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/0af6fd9d3636fd6403c7ada6c8a10530.jpg: 640x480 1 red ball, 2 humans, 13.9ms\n",
      "Speed: 2.2ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 0af6fd9d3636fd6403c7ada6c8a10530.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/11cb69ea752cefa3a8cad413598028de.jpg: 640x480 1 red ball, 8 humans, 13.3ms\n",
      "Speed: 2.4ms preprocess, 13.3ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 11cb69ea752cefa3a8cad413598028de.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/380fca853fd511698abe9f0c24285f68.jpg: 640x480 (no detections), 12.2ms\n",
      "Speed: 2.1ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 380fca853fd511698abe9f0c24285f68.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/7dbbf64f4372e8af631d5b3261e5d6aa.jpg: 640x480 1 human, 12.5ms\n",
      "Speed: 2.2ms preprocess, 12.5ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 7dbbf64f4372e8af631d5b3261e5d6aa.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/29b6473d55641a2d6a06276b9357090f.jpg: 640x480 1 human, 21.0ms\n",
      "Speed: 2.5ms preprocess, 21.0ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 29b6473d55641a2d6a06276b9357090f.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/9ecb763ade7cb05b25ab6f784d29744f.jpg: 640x480 3 humans, 12.4ms\n",
      "Speed: 2.0ms preprocess, 12.4ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 9ecb763ade7cb05b25ab6f784d29744f.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/f6448893a6bb9e4fa65a51298149599d.jpg: 640x480 1 human, 12.5ms\n",
      "Speed: 2.3ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì f6448893a6bb9e4fa65a51298149599d.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/d3ca9f15b02c341da0ca6cbb8d763a09.jpg: 640x480 1 human, 12.2ms\n",
      "Speed: 2.0ms preprocess, 12.2ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì d3ca9f15b02c341da0ca6cbb8d763a09.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/1104093f8577602bb0425f1ccd118de9.jpg: 640x480 1 red ball, 2 humans, 12.3ms\n",
      "Speed: 2.4ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 1104093f8577602bb0425f1ccd118de9.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/98a670c874d1cefcacd71b855d29769a.jpg: 640x480 (no detections), 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 98a670c874d1cefcacd71b855d29769a.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/d8ce4c69557862b45c0f7c18d0d3a412.jpg: 640x480 1 red ball, 1 human, 13.2ms\n",
      "Speed: 2.4ms preprocess, 13.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì d8ce4c69557862b45c0f7c18d0d3a412.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/e1117a3b7a26ccff17879b5789f02d0b.jpg: 640x480 1 human, 12.2ms\n",
      "Speed: 2.2ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì e1117a3b7a26ccff17879b5789f02d0b.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/d634b2ebe37b5735c16949926ae2d7bb.jpg: 640x480 3 humans, 12.3ms\n",
      "Speed: 1.9ms preprocess, 12.3ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì d634b2ebe37b5735c16949926ae2d7bb.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/8dad2db8365784c4b162442bd59eb5c7.jpg: 640x480 (no detections), 15.6ms\n",
      "Speed: 2.4ms preprocess, 15.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 8dad2db8365784c4b162442bd59eb5c7.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/7efdcca6d152b996a788f1694d0f62f9.jpg: 640x480 1 human, 12.5ms\n",
      "Speed: 2.0ms preprocess, 12.5ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì 7efdcca6d152b996a788f1694d0f62f9.jpg\n",
      "\n",
      "image 1/1 /home/tonino/projects/ball segmentation/datasets/ready/full_dataset/val/images/b5a9eceece731289df933a2d89cd24db.jpg: 640x480 1 red ball, 1 human, 13.1ms\n",
      "Speed: 2.0ms preprocess, 13.1ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001b[1m/home/tonino/projects/ball segmentation/runs/segment/predict8\u001b[0m\n",
      "  ‚úì b5a9eceece731289df933a2d89cd24db.jpg\n",
      "\n",
      "Results saved to: runs/segment/ball_person_model\n"
     ]
    }
   ],
   "source": [
    "# Load best model\n",
    "# best_model_path = RUNS_DIR / 'ball_person_model' / 'weights' / 'last.pt'\n",
    "\n",
    "# Test on validation images (sample from val set)\n",
    "test_images = list((YOLO_DATASET / \"val\" / \"images\").glob(\"*\"))\n",
    "\n",
    "print(f\"Testing on {len(test_images)} sample images...\")\n",
    "\n",
    "for img_path in test_images:\n",
    "    results = model.predict(str(img_path), save=True, conf=0.25)\n",
    "    print(f\"  ‚úì {img_path.name}\")\n",
    "\n",
    "print(f\"\\nResults saved to: {RUNS_DIR / 'ball_person_model'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
